{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ad4d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion Producto=68 . Lunes 1 de Julio esta es la que mejor decodifica de madrugda\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Paso 1: Cargar el dataset original\n",
    "df = pd.read_csv('./datasets/item_features.csv', encoding='utf-8')\n",
    "\n",
    "# Cargar el JSON con las categorías\n",
    "with open('literales.json', 'r', encoding='utf-8') as f:\n",
    "    categorias = json.load(f)\n",
    "\n",
    "# JSON con características específicas de calzado\n",
    "caracteristicas_calzado = {\n",
    "    \"tipos_de_suela_calzado\": [\n",
    "        \"plana\", \"tacón\", \"plataforma\", \"cuña\", \"suela de goma\", \"suela de madera\", \"suela antideslizante\", \n",
    "        \"suela de corcho\", \"suela de esparto\"\n",
    "    ],\n",
    "    \"tipos_de_tacon_calzado\": [\n",
    "        \"stiletto\", \"cuña\", \"bloque\", \"kitten\", \"aguja\", \"plataforma\", \"tacón ancho\", \"tacón bajo\", \"tacón alto\"\n",
    "    ],\n",
    "    \"tipos_de_puntera_calzado\": [\n",
    "        \"redonda\", \"puntiaguda\", \"abierta\", \"cuadrada\", \"en almendra\", \"puntera reforzada\", \"puntera metálica\", \n",
    "        \"puntera descubierta\", \"puntera texturizada\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Características específicas de accesorios\n",
    "caracteristicas_accesorios = {\n",
    "    \"tipos_de_gafas\": [\n",
    "        \"sol\", \"graduadas\", \"deportivas\", \"de lectura\"\n",
    "    ],\n",
    "    \"tipos_de_joyeria\": [\n",
    "        \"pendientes\", \"anillos\", \"pulseras\", \"collares\", \"broches\", \"tobilleras\", \n",
    "        \"colgantes\", \"relojes\", \"gemelos\"\n",
    "    ],\n",
    "    \"tipos_de_bolsos\": [\n",
    "        \"de mano\", \"bandolera\", \"mochila\", \"tote\", \"clutch\", \"hobo\", \"bolsa de playa\", \n",
    "        \"bolsa de viaje\", \"riñonera\"\n",
    "    ],\n",
    "    \"tipos_de_sombreros\": [\n",
    "        \"gorra\", \"sombrero de ala\", \"boina\", \"fedora\", \"panamá\", \"cloché\", \"sombrero cowboy\", \n",
    "        \"boina francesa\", \"sombrero bombín\"\n",
    "    ],\n",
    "    \"tipos_de_corbatas\": [\n",
    "        \"tradicional\", \"pajarita\", \"pañuelo de cuello\", \"corbata delgada\", \"ascot\", \n",
    "        \"corbata reversible\", \"corbata estampada\", \"corbata tejida\", \"corbata estrecha\"\n",
    "    ],\n",
    "    \"materiales\": [\n",
    "      \"Plástico\", \"Acero inoxidable\", \"Plata\", \"Oro\",\"Fibra de carbono\", \"PVC\"\n",
    "  ],\n",
    "}\n",
    "\n",
    "# Lista de tipos específicos de calzado\n",
    "tipos_calzado = [\n",
    "    \"Zapatillas deportivas\", \"Sandalias\", \"Botas\", \"Zapatos de salón\", \"Zapatillas de casa\", \"Botas de agua\",\n",
    "    \"Botas de montaña\", \"Zapatillas\", \"Bailarinas\", \"Mocasines\", \"Zuecos\", \"Zapatos de plataforma\", \"Zapatillas de Paseo\",\n",
    "    \"Botines\", \"Sandalias de caballero\"\n",
    "]\n",
    "\n",
    "# Lista de tipos específicos de accesorios\n",
    "tipos_accesorios = [\n",
    "    \"Bolso bandolera\", \"Mochila\", \"Cartera\", \"Bufanda\", \"Guantes\", \"Pañuelo\", \"Gorra\", \n",
    "    \"Gafas de sol\", \"Reloj\", \"Pulsera\", \"Collar\", \"Sombrero\", \"Turbante\", \"Corbata\", \n",
    "    \"Calcetines\", \"Pendientes\", \"Pulsera de tobillo\", \"Diadema\", \"Anillo\", \"Cinturon\", \n",
    "    \"Tirantes\", \"Gemelos\", \"Medias\"\n",
    "]\n",
    "\n",
    "# Paso 2: Definir el mapeo de valores para feature_category_id\n",
    "mapeo_valores = {\n",
    "    56: \"rangos_de_precio\",\n",
    "    68: \"productos\",\n",
    "    50: \"talla\",\n",
    "    47: \"materiales\",\n",
    "    61: \"estaciones\",\n",
    "    72: \"estampados\",\n",
    "    69: \"detalles\",\n",
    "    7: \"caracteristicas\",\n",
    "    55: \"marca\",\n",
    "    30: \"colores\",\n",
    "    4: \"ocasion\",\n",
    "    32: \"generos\",\n",
    "    19: \"pais_de_fabricacion\"\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# Función para verificar si el producto es calzado\n",
    "def es_calzado(row):\n",
    "    producto = row['feature_category_id']\n",
    "    nombre_producto = row['feature_value_id']\n",
    "    return producto == 68 and nombre_producto in tipos_calzado\n",
    "\n",
    "# Función para verificar si el producto es un accesorio\n",
    "def es_accesorio(row):\n",
    "    producto = row['feature_category_id']\n",
    "    nombre_producto = row['feature_value_id']\n",
    "    return producto == 68 and nombre_producto in tipos_accesorios\n",
    "\n",
    "# Paso 3: Añadir la columna 'category_literal' basada en el mapeo\n",
    "df['category_literal'] = df['feature_category_id'].map(mapeo_valores)\n",
    "\n",
    "# Paso 4: Añadir la columna 'feature_literal' basada en las características específicas de calzado o accesorios\n",
    "# Creamos un diccionario para almacenar el siguiente índice a asignar para cada categoría\n",
    "indice_por_categoria = {cat: 0 for cat in categorias.keys()}\n",
    "indice_por_categoria_calzado = {cat: 0 for cat in caracteristicas_calzado.keys()}\n",
    "indice_por_categoria_accesorios = {cat: 0 for cat in caracteristicas_accesorios.keys()}\n",
    "\n",
    "# Diccionario para almacenar las asignaciones previas de (feature_category_id, feature_value_id)\n",
    "asignaciones_previas = {}\n",
    "\n",
    "# Función para obtener el siguiente valor de la categoría\n",
    "def obtener_siguiente_valor(categoria):\n",
    "    valores = categorias[categoria]\n",
    "    indice_actual = indice_por_categoria[categoria]\n",
    "    valor = valores[indice_actual]\n",
    "    indice_por_categoria[categoria] = (indice_actual + 1) % len(valores)  # Circular por la lista de valores\n",
    "    return valor\n",
    "\n",
    "# Función para obtener el siguiente valor de características específicas de calzado\n",
    "def obtener_siguiente_valor_calzado(categoria):\n",
    "    valores = caracteristicas_calzado.get(categoria, [])\n",
    "    if valores:  # Verifica que la lista no esté vacía\n",
    "        indice_actual = indice_por_categoria_calzado[categoria]\n",
    "        valor = valores[indice_actual]\n",
    "        indice_por_categoria_calzado[categoria] = (indice_actual + 1) % len(valores)  # Circular por la lista de valores\n",
    "        return valor\n",
    "    else:\n",
    "        return obtener_siguiente_valor(categoria)\n",
    "\n",
    "# Función para obtener el siguiente valor de características específicas de accesorios\n",
    "def obtener_siguiente_valor_accesorios(categoria):\n",
    "    valores = caracteristicas_accesorios.get(categoria, [])\n",
    "    if valores:  # Verifica que la lista no esté vacía\n",
    "        indice_actual = indice_por_categoria_accesorios[categoria]\n",
    "        valor = valores[indice_actual]\n",
    "        indice_por_categoria_accesorios[categoria] = (indice_actual + 1) % len(valores)  # Circular por la lista de valores\n",
    "        return valor\n",
    "    else:\n",
    "        return obtener_siguiente_valor(categoria)\n",
    "\n",
    "# Iterar sobre las filas y asignar 'feature_literal'\n",
    "def asignar_feature_literal(row):\n",
    "    feature_id = row['feature_category_id']\n",
    "    feature_value_id = row['feature_value_id']\n",
    "    categoria = row['category_literal']\n",
    "    \n",
    "    if pd.isna(categoria):  # Manejar el caso donde 'category_literal' es NaN\n",
    "        return np.nan\n",
    "    \n",
    "    # Crear una clave para la combinación de feature_category_id y feature_value_id\n",
    "    clave = (feature_id, feature_value_id)\n",
    "    \n",
    "    # Usar la asignación previa si existe\n",
    "    if clave in asignaciones_previas:\n",
    "        return asignaciones_previas[clave]\n",
    "\n",
    "    # Asignar un nuevo valor\n",
    "    if es_calzado(row):\n",
    "        valor = obtener_siguiente_valor_calzado(categoria)\n",
    "    elif es_accesorio(row):\n",
    "        valor = obtener_siguiente_valor_accesorios(categoria)\n",
    "    else:\n",
    "        valor = obtener_siguiente_valor(categoria)\n",
    "    \n",
    "    # Guardar la asignación para futuros usos\n",
    "    asignaciones_previas[clave] = valor\n",
    "    \n",
    "    return valor\n",
    "\n",
    "df['feature_literal'] = df.apply(asignar_feature_literal, axis=1)\n",
    "\n",
    "#Duplico id para analisis posterior en excel\n",
    "df['bis'] = df['item_id']\n",
    "\n",
    "# Paso 5: Guardar el DataFrame actualizado en un nuevo archivo CSV\n",
    "df.to_csv('items3_conliterales.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8292eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcion Producto=68 . Lunes 1 de Julio esta es la que mejor decodifica a las 10.30\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Paso 1: Cargar el dataset original\n",
    "df = pd.read_csv('./datasets/item_features.csv', encoding='utf-8')\n",
    "\n",
    "# Cargar el JSON con las categorías\n",
    "with open('literales.json', 'r', encoding='utf-8') as f:\n",
    "    categorias = json.load(f)\n",
    "\n",
    "# JSON con características específicas de calzado\n",
    "caracteristicas_calzado = {\n",
    "    \"tipos_de_suela_calzado\": [\n",
    "        \"plana\", \"tacón\", \"plataforma\", \"cuña\", \"suela de goma\", \"suela de madera\", \"suela antideslizante\", \n",
    "        \"suela de corcho\", \"suela de esparto\"\n",
    "    ],\n",
    "    \"tipos_de_tacon_calzado\": [\n",
    "        \"stiletto\", \"cuña\", \"bloque\", \"kitten\", \"aguja\", \"plataforma\", \"tacón ancho\", \"tacón bajo\", \"tacón alto\"\n",
    "    ],\n",
    "    \"tipos_de_puntera_calzado\": [\n",
    "        \"redonda\", \"puntiaguda\", \"abierta\", \"cuadrada\", \"en almendra\", \"puntera reforzada\", \"puntera metálica\", \n",
    "        \"puntera descubierta\", \"puntera texturizada\"\n",
    "    ],\n",
    "    \"materiales\": [\n",
    "        \"Piel sintética\", \"Cuero\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Características específicas de accesorios\n",
    "caracteristicas_accesorios = {\n",
    "    \"tipos_de_gafas\": [\n",
    "        \"sol\", \"graduadas\", \"deportivas\", \"de lectura\"\n",
    "    ],\n",
    "    \"tipos_de_joyeria\": [\n",
    "        \"pendientes\", \"anillos\", \"pulseras\", \"collares\", \"broches\", \"tobilleras\", \n",
    "        \"colgantes\", \"relojes\", \"gemelos\"\n",
    "    ],\n",
    "    \"tipos_de_bolsos\": [\n",
    "        \"de mano\", \"bandolera\", \"mochila\", \"tote\", \"clutch\", \"hobo\", \"bolsa de playa\", \n",
    "        \"bolsa de viaje\", \"riñonera\"\n",
    "    ],\n",
    "    \"tipos_de_sombreros\": [\n",
    "        \"gorra\", \"sombrero de ala\", \"boina\", \"fedora\", \"panamá\", \"cloché\", \"sombrero cowboy\", \n",
    "        \"boina francesa\", \"sombrero bombín\"\n",
    "    ],\n",
    "    \"tipos_de_corbatas\": [\n",
    "        \"tradicional\", \"pajarita\", \"pañuelo de cuello\", \"corbata delgada\", \"ascot\", \n",
    "        \"corbata reversible\", \"corbata estampada\", \"corbata tejida\", \"corbata estrecha\"\n",
    "    ],\n",
    "    \"materiales\": [\n",
    "        \"Plástico\", \"Acero inoxidable\", \"Plata\", \"Oro\", \"Fibra de carbono\", \"PVC\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Lista de tipos específicos de calzado\n",
    "tipos_calzado = [\n",
    "    \"Zapatillas deportivas\", \"Sandalias\", \"Botas\", \"Zapatos de salón\", \"Zapatillas de casa\", \"Botas de agua\",\n",
    "    \"Botas de montaña\", \"Zapatillas\", \"Bailarinas\", \"Mocasines\", \"Zuecos\", \"Zapatos de plataforma\", \"Zapatillas de Paseo\",\n",
    "    \"Botines\", \"Sandalias de caballero\"\n",
    "]\n",
    "\n",
    "# Lista de tipos específicos de accesorios\n",
    "tipos_accesorios = [\n",
    "    \"Bolso bandolera\", \"Mochila\", \"Cartera\", \"Bufanda\", \"Guantes\", \"Pañuelo\", \"Gorra\", \n",
    "    \"Gafas de sol\", \"Reloj\", \"Pulsera\", \"Collar\", \"Sombrero\", \"Turbante\", \"Corbata\", \n",
    "    \"Calcetines\", \"Pendientes\", \"Pulsera de tobillo\", \"Diadema\", \"Anillo\", \"Cinturon\", \n",
    "    \"Tirantes\", \"Gemelos\", \"Medias\"\n",
    "]\n",
    "\n",
    "# Paso 2: Definir el mapeo de valores para feature_category_id\n",
    "mapeo_valores = {\n",
    "    56: \"rangos_de_precio\",\n",
    "    68: \"productos\",\n",
    "    50: \"talla\",\n",
    "    47: \"materiales\",\n",
    "    61: \"estaciones\",\n",
    "    72: \"estampados\",\n",
    "    69: \"detalles\",\n",
    "    7: \"caracteristicas\",\n",
    "    55: \"marca\",\n",
    "    30: \"colores\",\n",
    "    4: \"ocasion\",\n",
    "    32: \"generos\",\n",
    "    19: \"pais_de_fabricacion\"\n",
    "}\n",
    "\n",
    "# Función para verificar si el producto es calzado\n",
    "def es_calzado(row):\n",
    "    producto = row['feature_category_id']\n",
    "    nombre_producto = row['feature_value_id']\n",
    "    return producto == 68 and nombre_producto in tipos_calzado\n",
    "\n",
    "# Función para verificar si el producto es un accesorio\n",
    "def es_accesorio(row):\n",
    "    producto = row['feature_category_id']\n",
    "    nombre_producto = row['feature_value_id']\n",
    "    return producto == 68 and nombre_producto in tipos_accesorios\n",
    "\n",
    "# Paso 3: Añadir la columna 'category_literal' basada en el mapeo\n",
    "df['category_literal'] = df['feature_category_id'].map(mapeo_valores)\n",
    "\n",
    "# Paso 4: Añadir la columna 'feature_literal' basada en las características específicas de calzado o accesorios\n",
    "# Creamos un diccionario para almacenar el siguiente índice a asignar para cada categoría\n",
    "indice_por_categoria = {cat: 0 for cat in categorias.keys()}\n",
    "indice_por_categoria_calzado = {cat: 0 for cat in caracteristicas_calzado.keys()}\n",
    "indice_por_categoria_accesorios = {cat: 0 for cat in caracteristicas_accesorios.keys()}\n",
    "\n",
    "# Diccionario para almacenar las asignaciones previas de (feature_category_id, feature_value_id)\n",
    "asignaciones_previas = {}\n",
    "\n",
    "# Función para obtener el siguiente valor de la categoría\n",
    "def obtener_siguiente_valor(categoria):\n",
    "    valores = categorias[categoria]\n",
    "    indice_actual = indice_por_categoria[categoria]\n",
    "    valor = valores[indice_actual]\n",
    "    indice_por_categoria[categoria] = (indice_actual + 1) % len(valores)  # Circular por la lista de valores\n",
    "    return valor\n",
    "\n",
    "# Función para obtener el siguiente valor de características específicas de calzado\n",
    "def obtener_siguiente_valor_calzado(categoria):\n",
    "    valores = caracteristicas_calzado.get(categoria, [])\n",
    "    if valores:  # Verifica que la lista no esté vacía\n",
    "        indice_actual = indice_por_categoria_calzado[categoria]\n",
    "        valor = valores[indice_actual]\n",
    "        indice_por_categoria_calzado[categoria] = (indice_actual + 1) % len(valores)  # Circular por la lista de valores\n",
    "        return valor\n",
    "    else:\n",
    "        return obtener_siguiente_valor(categoria)\n",
    "\n",
    "# Función para obtener el siguiente valor de características específicas de accesorios\n",
    "def obtener_siguiente_valor_accesorios(categoria):\n",
    "    valores = caracteristicas_accesorios.get(categoria, [])\n",
    "    if valores:  # Verifica que la lista no esté vacía\n",
    "        indice_actual = indice_por_categoria_accesorios[categoria]\n",
    "        valor = valores[indice_actual]\n",
    "        indice_por_categoria_accesorios[categoria] = (indice_actual + 1) % len(valores)  # Circular por la lista de valores\n",
    "        return valor\n",
    "    else:\n",
    "        return obtener_siguiente_valor(categoria)\n",
    "\n",
    "# Iterar sobre las filas y asignar 'feature_literal'\n",
    "def asignar_feature_literal(row):\n",
    "    feature_id = row['feature_category_id']\n",
    "    feature_value_id = row['feature_value_id']\n",
    "    categoria = row['feature_category_literal']\n",
    "    \n",
    "    if pd.isna(categoria):  # Manejar el caso donde 'category_literal' es NaN\n",
    "        return np.nan\n",
    "    \n",
    "    # Crear una clave para la combinación de feature_category_id y feature_value_id\n",
    "    clave = (feature_id, feature_value_id)\n",
    "    \n",
    "    # Usar la asignación previa si existe\n",
    "    if clave in asignaciones_previas:\n",
    "        return asignaciones_previas[clave]\n",
    "\n",
    "    # Asignar un nuevo valor\n",
    "    if es_calzado(row):\n",
    "        if categoria == 'materiales':\n",
    "            valor = obtener_siguiente_valor_calzado(categoria)\n",
    "        else:\n",
    "            valor = obtener_siguiente_valor_calzado(categoria)\n",
    "    elif es_accesorio(row):\n",
    "        if categoria == 'materiales':\n",
    "            valor = obtener_siguiente_valor_accesorios(categoria)\n",
    "        else:\n",
    "            valor = obtener_siguiente_valor_accesorios(categoria)\n",
    "    else:\n",
    "        valor = obtener_siguiente_valor(categoria)\n",
    "    \n",
    "    # Guardar la asignación para futuros usos\n",
    "    asignaciones_previas[clave] = valor\n",
    "    \n",
    "    return valor\n",
    "\n",
    "df['feature_value_literal'] = df.apply(asignar_feature_literal, axis=1)\n",
    "\n",
    "# Duplicar id para análisis posterior en excel\n",
    "df['item_id_2'] = df['item_id']\n",
    "\n",
    "# Paso 5: Guardar el DataFrame actualizado en un nuevo archivo CSV\n",
    "df.to_csv('./item_features_semirelleno_con_literales.csv', index=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ab3f8",
   "metadata": {},
   "source": [
    "### Comprabaciones y chequeos previos al cuadre de ... \n",
    "### literales(feature_category_literal/feature_value_literal) y identificadores (feature_category_id/feature_value_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e09d3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asignados:\n",
      "feature_category_id\n",
      "4                 [ocasion]\n",
      "7         [caracteristicas]\n",
      "19    [pais_de_fabricacion]\n",
      "30                [colores]\n",
      "32                [generos]\n",
      "47             [materiales]\n",
      "50                  [talla]\n",
      "55                  [marca]\n",
      "56       [rangos_de_precio]\n",
      "61             [estaciones]\n",
      "68              [productos]\n",
      "69               [detalles]\n",
      "72             [estampados]\n",
      "Name: feature_category_literal, dtype: object\n",
      "\n",
      "No asignados:\n",
      "{1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 70, 71, 73}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el fichero CSV\n",
    "df = pd.read_csv('./item_features_semirelleno_con_literales.csv')\n",
    "\n",
    "# Filtrar filas donde el feature_category_literal no es nulo\n",
    "assigned_literals = df[df['feature_category_literal'].notna()]\n",
    "\n",
    "# Agrupar por feature_category_id y obtener los literales únicos asociados\n",
    "category_analysis = assigned_literals.groupby('feature_category_id')['feature_category_literal'].unique()\n",
    "\n",
    "# Convertir el resultado a un diccionario para su análisis\n",
    "category_analysis_dict = category_analysis #.to_dict()\n",
    "\n",
    "# Obtener todos los feature_category_id presentes en el CSV\n",
    "all_category_ids = df['feature_category_id'].unique()\n",
    "\n",
    "# Identificar los feature_category_id que no tienen literal asignado\n",
    "unassigned_category_ids = set(all_category_ids) - set(category_analysis_dict.keys())\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Asignados:\")\n",
    "print(category_analysis_dict)\n",
    "print(\"\\nNo asignados:\")\n",
    "print(unassigned_category_ids)\n",
    "\n",
    "# Opcionalmente, guardar los resultados en variables para su uso posterior\n",
    "assigned_dict = category_analysis_dict\n",
    "unassigned_list = list(unassigned_category_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5f8efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['materiales', 'talla', 'productos', 'generos', 'estaciones', 'colores', 'ocasion', 'caracteristicas', 'estampados', 'detalles', 'tipos_de_corte', 'tipos_de_cuello', 'tipos_de_cintura', 'tipos_de_manga', 'tipos_de_cierre', 'tipos_de_bolsillos', 'tipos_de_suela_calzado', 'tipos_de_tacon_calzado', 'tipos_de_puntera_calzado', 'tipos_de_gafas', 'tipos_de_joyeria', 'tipos_de_bolsos', 'tipos_de_sombreros', 'tipos_de_corbatas', 'material_del_forro', 'material_del_relleno', 'transpirabilidad', 'impermeabilidad', 'durabilidad', 'facilidad_de_cuidado', 'resistencia_a_las_arrugas', 'elasticidad', 'suavidad', 'peso', 'calidez', 'resistencia_a_la_decoloracion', 'resistencia_al_encogimiento', 'resistencia_a_la_pilling', 'resistencia_a_la_abrasion', 'resistencia_a_los_rayos_uv', 'resistencia_al_fuego', 'resistencia_a_las_manchas', 'resistencia_al_agua', 'resistencia_al_viento', 'resistencia_a_los_olores', 'resistencia_a_los_insectos', 'resistencia_a_los_microbios', 'biodegradabilidad', 'reciclabilidad', 'origen_del_material', 'certificaciones_ecologicas', 'certificaciones_comercio_justo', 'certificaciones_bienestar_animal', 'certificaciones_condiciones_laborales', 'rangos_de_precio', 'marca', 'Marca Nacional', 'pais_de_fabricacion', 'garantia', 'politica_de_devoluciones', 'disponibilidad', 'tiempo_de_entrega', 'opciones_de_personalizacion', 'instrucciones_de_cuidado', 'tipo_de_tela', 'tipo_de_ajuste_ropa', 'tipo_de_ajuste_calzado', 'tipo_de_soporte_calzado', 'tipo_de_lente_gafas', 'tipo_de_montura_gafas', 'tipo_de_piedra_joyeria', 'tipo_de_metal_joyeria', 'tipo_de_cierre_joyeria', 'tipo_de_asa_bolsos']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Cargar el fichero JSON\n",
    "with open('./literales.json', 'r', encoding='utf-8') as f:\n",
    "    category_data = json.load(f)\n",
    "\n",
    "# Obtener los nombres de las categorías (las claves principales del JSON)\n",
    "category_literals = list(category_data.keys())\n",
    "\n",
    "# Mostrar los literales de las categorías\n",
    "print(category_literals)\n",
    "\n",
    "# Opcionalmente, guardar los literales en una variable para su uso posterior\n",
    "category_literals_list = category_literals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802fab6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Literales asignados:\n",
      "{'caracteristicas', 'talla', 'generos', 'materiales', 'detalles', 'marca', 'pais_de_fabricacion', 'estaciones', 'rangos_de_precio', 'productos', 'estampados', 'colores', 'ocasion'}\n",
      "\n",
      "Literales no asignados:\n",
      "{'durabilidad', 'resistencia_a_los_rayos_uv', 'certificaciones_comercio_justo', 'peso', 'tipo_de_tela', 'resistencia_al_viento', 'certificaciones_ecologicas', 'tipos_de_corte', 'tipo_de_ajuste_calzado', 'tipos_de_corbatas', 'tipos_de_cuello', 'tipo_de_montura_gafas', 'resistencia_al_encogimiento', 'tipos_de_cierre', 'suavidad', 'certificaciones_condiciones_laborales', 'opciones_de_personalizacion', 'tipos_de_bolsos', 'resistencia_a_los_microbios', 'instrucciones_de_cuidado', 'disponibilidad', 'garantia', 'tipo_de_cierre_joyeria', 'tipos_de_suela_calzado', 'tipo_de_asa_bolsos', 'material_del_forro', 'resistencia_al_agua', 'resistencia_a_la_decoloracion', 'tipos_de_joyeria', 'biodegradabilidad', 'Marca Nacional', 'elasticidad', 'resistencia_a_las_arrugas', 'certificaciones_bienestar_animal', 'facilidad_de_cuidado', 'tipos_de_cintura', 'origen_del_material', 'tipo_de_lente_gafas', 'tipo_de_metal_joyeria', 'tipos_de_sombreros', 'calidez', 'politica_de_devoluciones', 'resistencia_a_las_manchas', 'tipos_de_bolsillos', 'tipos_de_gafas', 'resistencia_al_fuego', 'tipo_de_piedra_joyeria', 'tipo_de_soporte_calzado', 'impermeabilidad', 'material_del_relleno', 'resistencia_a_los_olores', 'resistencia_a_la_abrasion', 'tiempo_de_entrega', 'reciclabilidad', 'tipos_de_tacon_calzado', 'tipos_de_manga', 'transpirabilidad', 'tipo_de_ajuste_ropa', 'resistencia_a_los_insectos', 'resistencia_a_la_pilling', 'tipos_de_puntera_calzado'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar el fichero JSON\n",
    "with open('./literales.json', 'r', encoding='utf-8') as f:\n",
    "    category_data = json.load(f)\n",
    "\n",
    "# Obtener los nombres de las categorías del JSON\n",
    "category_literals_json = set(category_data.keys())\n",
    "\n",
    "# Cargar el fichero CSV\n",
    "df = pd.read_csv('./item_features_semirelleno_con_literales.csv')\n",
    "\n",
    "# Obtener los literales ya asignados en el CSV\n",
    "assigned_literals_csv = set(df['feature_category_literal'].dropna().unique())\n",
    "\n",
    "# Determinar los literales asignados y no asignados\n",
    "assigned_literals = category_literals_json.intersection(assigned_literals_csv)\n",
    "unassigned_literals = category_literals_json - assigned_literals_csv\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Literales asignados:\")\n",
    "print(assigned_literals)\n",
    "print(\"\\nLiterales no asignados:\")\n",
    "print(unassigned_literals)\n",
    "\n",
    "# Opcionalmente, guardar los resultados en variables para su uso posterior\n",
    "assigned_literals_set = assigned_literals\n",
    "unassigned_literals_set = unassigned_literals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ddd96",
   "metadata": {},
   "source": [
    "### Análisis de literales e identificadores no asignados (19/ago/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d7a979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(csv)Número total de combinaciones distintas: 904\n",
      "(csv)Número de identificadores de categorías asociados ya 13\n",
      "(csv)Número de todas los categorias 73\n",
      "(csv)Número de identificadores de categorías sin asignar 60\n",
      "--------------------------------------------------------------\n",
      "Total de combinaciones no asignadas: 487\n",
      "Total de combinaciones asignadas: 417\n",
      "Total: 904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{4: 16,\n",
       " 7: 35,\n",
       " 19: 30,\n",
       " 30: 67,\n",
       " 32: 5,\n",
       " 47: 17,\n",
       " 50: 24,\n",
       " 55: 49,\n",
       " 56: 67,\n",
       " 61: 5,\n",
       " 68: 48,\n",
       " 69: 29,\n",
       " 72: 25}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el fichero CSV\n",
    "# -item_features_semirelleno_con_literales.csv es el fichero original-\n",
    "df = pd.read_csv('./item_features_semirelleno_con_literales_actualizado.csv')\n",
    "\n",
    "# Obtener las combinaciones distintas de feature_category_id y feature_value_id\n",
    "distinct_combinations = df[['feature_category_id', 'feature_value_id']].drop_duplicates()\n",
    "\n",
    "# Mostrar las combinaciones distintas\n",
    "#print(\"Combinaciones distintas de feature_category_id y feature_value_id:\")\n",
    "#print(distinct_combinations)\n",
    "\n",
    "# Opcionalmente, contar el número de combinaciones distintas\n",
    "num_combinations = distinct_combinations.shape[0]\n",
    "print(f\"\\n(csv)Número total de combinaciones distintas: {num_combinations}\")\n",
    "\n",
    "\n",
    "# Filtrar filas donde el feature_category_literal no es nulo\n",
    "assigned_literals = df[df['feature_category_literal'].notna()]\n",
    "\n",
    "# Agrupar por feature_category_id y obtener los literales únicos asociados\n",
    "category_analysis = assigned_literals.groupby('feature_category_id')['feature_category_literal'].unique()\n",
    "print(f\"(csv)Número de identificadores de categorías asociados ya {len(category_analysis)}\")\n",
    "\n",
    "# Convertir el resultado a un diccionario para su análisis\n",
    "category_analysis_dict = category_analysis.to_dict()\n",
    "\n",
    "# Obtener todos los feature_category_id presentes en el CSV\n",
    "all_category_ids = df['feature_category_id'].unique()\n",
    "print(f\"(csv)Número de todas los categorias {len(all_category_ids)}\")\n",
    "\n",
    "# Identificar los feature_category_id que no tienen literal asignado\n",
    "unassigned_category_ids = set(all_category_ids) - set(category_analysis_dict.keys())\n",
    "\n",
    "# Filtrar filas donde el feature_value_id está vacío y el feature_category_id está en la lista de no asignados\n",
    "empty_value_df = df[(df['feature_value_literal'].isna()) & (df['feature_category_id'].isin(unassigned_category_ids))]\n",
    "\n",
    "# Agrupar por feature_category_id y recoger los feature_value_id correspondientes que están vacíos\n",
    "unassigned_category_values_dict = empty_value_df.groupby('feature_category_id')['feature_value_id'].unique().to_dict()\n",
    "\n",
    "# Ordenar el diccionario por el tamaño del array de feature_value_id's de mayor a menor\n",
    "sorted_unassigned_category_values = dict(sorted(unassigned_category_values_dict.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "\n",
    "# Mostrar los resultados\n",
    "#print(\"Feature Category IDs sin Literal Asignado ordenados por la cantidad de Feature Values Vacíos:\")\n",
    "#print(sorted_unassigned_category_values)\n",
    "\n",
    "print(f\"(csv)Número de identificadores de categorías sin asignar {len(sorted_unassigned_category_values)}\")\n",
    "\n",
    "\n",
    "print(\"--------------------------------------------------------------\")\n",
    "\n",
    "# Contar combinaciones distintas de feature_category_id y feature_value_id para sorted_unassigned_category_values\n",
    "unassigned_combination_counts = {}\n",
    "total1 = 0\n",
    "for category_id, value_ids in sorted_unassigned_category_values.items():\n",
    "    count = distinct_combinations[(distinct_combinations['feature_category_id'] == category_id) & \n",
    "                                  (distinct_combinations['feature_value_id'].isin(value_ids))].shape[0]\n",
    "    unassigned_combination_counts[category_id] = count\n",
    "    total1 += count\n",
    "print(f\"Total de combinaciones no asignadas: {total1}\")\n",
    "    \n",
    "# Contar combinaciones distintas de feature_category_id y feature_value_id para category_analysis\n",
    "assigned_combination_counts = {}\n",
    "total2 = 0\n",
    "for category_id in category_analysis_dict.keys():\n",
    "    count = distinct_combinations[distinct_combinations['feature_category_id'] == category_id].shape[0]\n",
    "    assigned_combination_counts[category_id] = count\n",
    "    total2 += count\n",
    "print(f\"Total de combinaciones asignadas: {total2}\")\n",
    "print (f\"Total: {total1+total2}\")    \n",
    "# Mostrar los resultados\n",
    "#print(\"Feature Category IDs sin Literal Asignado ordenados por la cantidad de Feature Values Vacíos y combinaciones distintas:\")\n",
    "#for category_id, value_ids in sorted_unassigned_category_values.items():\n",
    "#    print(f\"Category ID: {category_id}, Feature Values Vacíos: {len(value_ids)}, Combinaciones Distintas: {unassigned_combination_counts[category_id]}\")\n",
    "\n",
    "#print(f\"\\nNúmero total de identificadores de categorías sin asignar: {len(sorted_unassigned_category_values)}\")\n",
    "\n",
    "#print(\"\\nNúmero de combinaciones distintas para cada feature_category_id en category_analysis:\")\n",
    "#for category_id, count in assigned_combination_counts.items():\n",
    "#    print(f\"Category ID: {category_id}, Combinaciones Distintas: {count}\")\n",
    "#unassigned_combination_counts\n",
    "assigned_combination_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9a9a761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(json)Número de categorías de literales totales 73\n",
      "\n",
      "(json)Número total de combinaciones distintas: 904\n",
      "--------------------------------------------------------------\n",
      "Número de categorías de literales totales asignadas(csv) 13\n",
      "Número de categorías de literales totales asignadas(json) 13\n",
      "Número de categorías de literales totales sin asignar(json) 60\n",
      "--------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------\n",
      "Literales asignados con posibles valores, ordenados de mayor a menor por cantidad de valores:\n",
      "(67):colores:['Azul', 'Blanca', 'Blanco', 'Negro', 'Rojo', 'Azul oscuro', 'Verde', 'Marrón', 'Gris', 'Rosa', 'Amarillo', 'Beige', 'Multicolor', 'Dorado', 'Plateado', 'Morado', 'Cyan', 'Antracita', 'Turquesa', 'Naranja', 'Verde lima', 'Granate', 'Índigo', 'Salmón', 'Caqui', 'Verde oliva', 'Malva', 'Lila', 'Fucsia', 'Coral', 'Terracota', 'Burdeos', 'Mostaza', 'Amarillo mostaza', 'Ocre', 'Aqua', 'Azul cielo', 'Azul marino', 'Gris marengo', 'Gris perla', 'Blanco hueso', 'Blanco roto', 'Marfil', 'Melocotón', 'Menta', 'Pistacho', 'Salvia', 'Gris oscuro', 'Gris claro', 'Rosa pastel', 'Azul pastel', 'Verde menta', 'Beige claro', 'Beige oscuro', 'Azul petróleo', 'Verde esmeralda', 'Lavanda', 'Amaranto', 'Celeste', 'Magenta', 'Topo', 'Jade', 'Marengo', 'Verde botella', 'Púrpura', 'Beige arena', 'Turquesa claro']\n",
      "(67):rangos_de_precio:['10-12', '12-14', '14-16', '16-20', '20-22', '22-24', '24-26', '26-30', '30-32', '32-34', '34-36', '36-40', '40-42', '42-44', '44-46', '46-50', '50-52', '52-54', '54-56', '56-60', '60-62', '62-64', '64-66', '66-70', '70-72', '72-74', '74-76', '76-80', '80-82', '82-84', '84-86', '86-90', '90-92', '92-94', '94-96', '96-100', '100-110', '110-120', '120-130', '130-150', '150-160', '160-170', '170-180', '180-200', '200-210', '210-220', '220-230', '230-250', '250-260', '260-270', '270-280', '280-300', '300-310', '310-320', '320-330', '330-350', '350-360', '360-370', '370-380', '380-400', '400-410', '410-420', '420-430', '430-450', '450-500', '500-550', '550-600']\n",
      "(49):marca:['Adidas', 'Adolfo Domínguez', 'Balenciaga', 'Bershka', 'Burberry', 'Calvin Klein', 'Camper', 'Castañer', 'Chanel', 'Clarks', 'Coach', 'Converse', 'Crocs', 'Desigual', 'Givenchy', 'Diesel', 'Dior', 'Dr. Martens', 'El Ganso', 'Fossil', 'Gioseppo', 'Gucci', 'Guess', 'H&M', 'Hermès', 'Kate Spade', 'Levis', 'Louis Vuitton', 'Mango', 'Massimo Dutti', 'Michael Kors', 'Mustang', 'New Balance', 'Nike', 'Panama Jack', 'Pikolinos', 'Prada', 'Pull&Bear', 'Puma', 'Ralph Lauren', 'Reebok', 'Skechers', 'Stradivarius', 'Timberland', 'Tommy Hilfiger', 'Uniqlo', 'Valentino', 'Vans', 'Zara']\n",
      "(48):productos:['Abrigo', 'Americana', 'Bailarinas', 'Bikini', 'Blusa', 'Bolso bandolera', 'Bolso de mano', 'Botas', 'Botas de agua', 'Botas de montaña', 'Botines', 'Bufanda', 'Calcetines', 'Camiseta', 'Cartera', 'Cazadora', 'Chaleco', 'Chaqueta', 'Collar', 'Corbata', 'Falda', 'Gafas de sol', 'Gorra', 'Guantes', 'Kimono', 'Leggings', 'Mocasines', 'Mochila', 'Mono', 'Pantalon', 'Pañuelo', 'Pendientes', 'Pulsera', 'Pulsera de tobillo', 'Reloj', 'Sandalias', 'Sombrero', 'Sudadera', 'Top', 'Turbante', 'Vestido', 'Zapatillas', 'Zapatillas de Paseo', 'Zapatillas de casa', 'Zapatillas deportivas', 'Zapatos de plataforma', 'Zapatos de salón', 'Zuecos']\n",
      "(35):caracteristicas:['Manga larga', 'Manga corta', 'Largo', 'Corto', 'Completo', 'Tirantes', 'Con flecos', 'Elástico', 'Ajustable', 'Analógico', 'Plegable', 'Con borlas', 'Transpirable', 'Antiestático', 'Amortiguada', 'Alta tracción', 'Técnico', 'Resistente', 'Plana', 'Antideslizante', 'Comodo', 'Impermeable', 'Flexible', 'Adaptable', 'Ergonómico', 'Liviano', 'Reflector', 'Absorbente', 'Con refuerzos', 'Acolchado', 'Lavable', 'Sin costuras', 'Ignífugo', 'Térmico', 'Translucido']\n",
      "(30):pais_de_fabricacion:['Canadá', 'Bangladesh', 'Egipto', 'Países Bajos', 'México', 'Rumania', 'India', 'Polonia', 'China', 'Francia', 'Reino Unido', 'Ucrania', 'Italia', 'Nueva Zelanda', 'Portugal', 'Perú', 'Brasil', 'Japón', 'España', 'Etiopía', 'Indonesia', 'Estados Unidos', 'Corea del Sur', 'Vietnam', 'Australia', 'Túnez', 'Alemania', 'Turquía', 'Pakistán', 'Colombia']\n",
      "(29):detalles:['Con botones', 'Transpirable', 'Con capucha', 'Con forro', 'Con cremallera', 'Con encaje', 'Con cinturón', 'Sin costuras', 'Con cordón ajustable', 'Con protección UV', 'De Sastre', 'Con tachuelas', 'Con bolsillos laterales', 'Con compartimentos internos', 'Con visera', 'Con montura gruesa', 'Resistente al agua', 'Ajustable', 'Con piedras preciosas', 'Con tiras ajustables', 'Forradas', 'Con puntera', 'Entrenamiento', 'Senderismo', 'Baloncesto', 'Skateboarding', 'Golf', 'Verano', 'Cremallera']\n",
      "(25):estampados:['Abstracto', 'Animal print', 'Artístico', 'Azteca', 'Botánico', 'Camuflaje', 'Chevron', 'Cuadros', 'Difuminado', 'Estampado', 'Etnico', 'Floral', 'Galáctico', 'Geométrico', 'Liso', 'Marítimo', 'Militar', 'Mosaico', 'Paisley', 'Polka dots', 'Rayas', 'Retro', 'Tie-dye', 'Tropical', 'Vintage']\n",
      "(24):talla:['M', 'S', 'XS', 'L', 'XL', 'XXL', 'XXS', 'Unitalla', 'XXXL', 'XXXXL', 'XXXXXL', '0XL', '1XL', '2XL', '3XL', '4XL', '5XL', 'US2', 'US4', 'US6', 'US8', 'US10', 'US12', 'US14']\n",
      "(17):materiales:['Algodón', 'Seda', 'Denim', 'Cuero', 'Terciopelo', 'Lycra', 'Lana', 'Nylon', 'Lino', 'Viscosa', 'Fibra de carbono', 'Poliéster', 'Piel sintética', 'Plástico', 'Plata', 'Oro', 'Acero inoxidable']\n",
      "(16):ocasion:['Casual', 'Cóctel', 'Informal', 'Ceremonia', 'Fiesta', 'Diario', 'Elegante', 'Trabajo', 'Playa', 'Viaje', 'Noche', 'Universidad', 'Eventos Deportivos', 'Cita', 'Gala', 'Temporada Festiva']\n",
      "(5):generos:['Mujer', 'Hombre', 'Unisex', 'niño', 'bebe']\n",
      "(5):estaciones:['Primavera', 'Verano', 'Otoño', 'Invierno', 'Todo el año']\n",
      "Total 417 ------------------------------------------------------------------------------\n",
      "Literales no asignados con posibles valores, ordenados de mayor a menor por cantidad de valores:\n",
      "(27):material_del_forro:['algodón', 'poliéster', 'seda', 'lana', 'nylon', 'viscosa', 'rayón', 'terciopelo', 'satén', 'forro acolchado', 'forro de felpa', 'forro de microfibra', 'orro de polar', 'forro de gamuza', 'forro de algodón orgánico', 'forro impermeable', 'forro transpirable', 'forro resistente al agua', 'forro antiestático', 'forro de lana merina', 'forro de seda natural', 'forro de lana reciclada', 'forro de algodón reciclado', 'forro de cáñamo', 'forro de lino', 'forro de bambú', 'forro de vellón reciclado']\n",
      "(25):tipos_de_suela_calzado:['plana', 'tacón', 'plataforma', 'cuña', 'suela de goma', 'suela de madera', 'suela antideslizante', 'suela de corcho', 'suela de esparto', 'ecológica', 'goma reciclada', 'ultra-ligera', 'antideslizante avanzada', 'reforzada', 'carbono', 'amortiguación', 'aislamiento térmico', 'ergonómica', 'tracción extra', 'cuero', 'almohadillas', 'tecnología Gel', 'tecnología Air', 'tecnología EVA', 'corcho reciclado']\n",
      "(23):reciclabilidad:['reciclable', 'no reciclable', 'sostenibilidad', 'economía circular', 'reutilizable', 'reducción de residuos', 'eco-friendly', 'material renovable', 'eco-conciencia', 'material reciclado', 'reciclaje avanzado', 'compostable', 'reciclaje de fibra textil', 'reciclaje de tejido', 'reciclaje mecánico', 'reciclaje químico', 'reciclaje post-consumo', 'reciclaje pre-consumo', 'reutilización de materiales', 'reciclaje de metales', 'reciclaje de plástico reciclado', 'reciclaje de papel reciclado', 'reciclaje de vidrio reciclado']\n",
      "(21):resistencia_a_los_olores:['resistente a los olores', 'no resistente a los olores', 'tecnología anti-olor', 'prevención de olores', 'control de olores', 'neutralizador de olores', 'tejido fresco', 'anti-microbios', 'antibacteriano', 'tratamiento anti-hongos', 'resistente a la humedad', 'secado rápido', 'tratamiento de frescura duradera', 'material con ionización', 'tratamiento con carbón activado', 'protección anti-UV', 'tejido de alta ventilación', 'tratamiento antibacteriano avanzado', 'frescura prolongada', 'tratamiento con zinc antibacteriano', 'resistente a la transpiración']\n",
      "(18):tipos_de_cierre:['botones', 'cremallera', 'cordones', 'broche', 'velcro', 'corchete', 'hebilla', 'botón a presión', 'nudo', 'cremallera impermeable', 'cremallera invisible', 'cordones elásticos', 'cierre magnético', 'cierre de gancho', 'cierre con hebilla doble', 'cierre de encaje', 'cierre de doble botón', 'cierre de cinta']\n",
      "(17):resistencia_al_fuego:['resistente al fuego', 'no resistente al fuego', 'ignífugo', 'tejido ignífugo', 'protección contra el fuego', 'material retardante de llama', 'seguridad contra incendios', 'material ignifugo', 'tejido resistente a altas temperaturas', 'material autoextinguible', 'tejido sin combustión', 'resistente al calor extremo', 'tejido con retardante de llama', 'material ignífugo natural', 'tejido de alta seguridad', 'material anti-chispas', 'protección contra explosiones']\n",
      "(17):tipos_de_cuello:['redondo', 'en V', 'polo', 'cuello alto', 'cuello barco', 'cuello halter', 'halter', 'escote corazón', 'bardot', 'escote cuadrado', 'escote profundo', 'escote palabra de honor', 'cuello de cisne', 'escote lágrima', 'cuello mandarín', 'escote asimétrico', 'cuello drapeado']\n",
      "(17):tipos_de_bolsos:['de mano', 'bandolera', 'mochila', 'tote', 'clutch', 'hobo', 'bolsa de playa', 'bolsa de viaje', 'riñonera', 'de gimnasio', 'baguette', 'satchel', 'De cámara', 'bombonera', 'De pañales', 'messenger', 'De rafia']\n",
      "(16):material_del_relleno:['plumón', 'poliéster', 'algodón', 'espuma', 'lana', 'fibra de bambú', 'fibra de coco', 'fibra de maíz', 'gel de silicona', 'fibra hueca', 'microfibra', 'espuma viscoelástica', 'pluma de ganso', 'fibra reciclada', 'espuma de látex', 'fibra de soja']\n",
      "(14):certificaciones_ecologicas:['certificado orgánico', 'certificado ecológico', 'sin certificación', 'estándares ambientales', 'ecoetiquetas', 'huella de carbono', 'gestión forestal sostenible', 'eco-certificación', 'sello verde', 'certificación GOTS', 'certificación OEKO-TEX', 'producción libre de químicos', 'cero emisiones de carbono', 'residuos mínimos']\n",
      "(12):facilidad_de_cuidado:['lavable a máquina', 'solo limpieza en seco', 'lavable a mano', 'sin planchado', 'fácil mantenimiento', 'tejido antiarrugas', 'tejido de secado rápido', 'resistente al encogimiento', 'tejido antiolor', 'lavable a baja temperatura', 'resistente al pilling', 'secado rápido avanzado']\n",
      "(11):tipos_de_sombreros:['gorra', 'sombrero de ala', 'boina', 'fedora', 'panamá', 'cloché', 'sombrero cowboy', 'boina francesa', 'sombrero bombín', 'trilby', 'floppy']\n",
      "(11):certificaciones_condiciones_laborales:['certificado de condiciones laborales justas', 'sin certificación', 'derechos laborales', 'trabajo digno', 'seguridad laboral', 'equidad en el trabajo', 'protección del empleado', 'cumplimiento de normativas laborales', 'justicia laboral', 'certificación ISO 45001', 'programa de responsabilidad social']\n",
      "(11):tipos_de_manga:['corta', 'larga', 'sin mangas', 'tres cuartos', 'manga murciélago', 'manga globo', 'manga farol', 'manga mariposa', 'manga kimono', 'raglán', 'de campana']\n",
      "(11):tipos_de_corte:['recto', 'ajustado', 'suelto', 'acampanado', 'entallado', 'oversize', 'evase', 'asimetrico', 'tubo', 'A-line', 'sirena']\n",
      "(10):tipos_de_joyeria:['pendientes', 'anillos', 'pulseras', 'collares', 'broches', 'tobilleras', 'colgantes', 'relojes', 'gemelos', 'piercings']\n",
      "(10):tipos_de_gafas:['sol', 'graduadas', 'deportivas', 'de lectura', 'de seguridad', 'de natación', 'de realidad aumentada', 'gafas de buceo', 'gafas fotocromáticas', 'Gafas de esquí']\n",
      "(10):tipos_de_bolsillos:['con/sin bolsillos', 'bolsillos laterales', 'bolsillos traseros', 'bolsillos en el pecho', 'bolsillos internos', 'bolsillos cargo', 'bolsillo monedero', 'bolsillos con solapa', 'bolsillos ocultos', 'Bolsillos con cremallera']\n",
      "(10):tipos_de_corbatas:['tradicional', 'pajarita', 'pañuelo de cuello', 'corbata delgada', 'ascot', 'corbata reversible', 'corbata estampada', 'corbata tejida', 'corbata estrecha', 'bolo']\n",
      "(10):certificaciones_comercio_justo:['certificado de comercio justo', 'sin certificación', 'justicia social', 'condiciones laborales éticas', 'salarios dignos', 'igualdad en el trabajo', 'transparencia empresarial', 'ética en la cadena de suministro', 'respeto a los derechos humanos', 'Certificación ecológica']\n",
      "(8):transpirabilidad:['alta', 'media', 'baja', 'ultra transpirable', 'tejido ventilado', 'tecnología Dry-Fit', 'tecnología ClimaCool', 'tejido perforado']\n",
      "(8):resistencia_a_los_insectos:['resistente a los insectos', 'no resistente a los insectos', 'protección contra insectos', 'anti-mosquitos', 'tejido insecticida', 'barrera anti-insectos', 'protección al aire libre', 'seguridad contra plagas']\n",
      "(8):tipos_de_tacon_calzado:['cuña', 'bloque', 'kitten', 'aguja', 'plataforma', 'tacón ancho', 'tacón bajo', 'tacón alto']\n",
      "(8):origen_del_material:['natural', 'sintético', 'mixto', 'fuentes renovables', 'materia prima sostenible', 'responsable ambientalmente', 'procedencia ética', 'sostenibilidad']\n",
      "(7):tipos_de_puntera_calzado:['redonda', 'puntiaguda', 'abierta', 'cuadrada', 'en almendra', 'puntera reforzada', 'puntera descubierta']\n",
      "(7):biodegradabilidad:['biodegradable', 'no biodegradable', 'degradación natural', 'material compostable', 'reciclaje orgánico', 'ciclo de vida sostenible', 'biomaterial']\n",
      "(6):calidez:['alta', 'media', 'baja', 'extremadamente cálido', 'aislamiento térmico', 'tecnología ThermoShield']\n",
      "(6):elasticidad:['elástico', 'semi-elástico', 'no elástico', 'elasticidad multidireccional', 'flexibilidad máxima', 'ajuste adaptable']\n",
      "(6):durabilidad:['alta', 'media', 'baja', 'extremadamente durable', 'resistente a la abrasión', 'resistencia al desgaste']\n",
      "(6):resistencia_al_encogimiento:['alta', 'media', 'baja', 'mínimo encogimiento', 'sin encogimiento', 'tejido preencogido']\n",
      "(6):resistencia_a_la_abrasion:['alta', 'media', 'baja', 'tejido resistente a la abrasión', 'durabilidad extrema', 'resistencia al roce']\n",
      "(6):resistencia_a_los_microbios:['resistente a los microbios', 'no resistente a los microbios', 'tecnología antimicrobiana', 'antivirus', 'desinfección natural', 'tejido hipoalergénico']\n",
      "(6):resistencia_a_la_decoloracion:['alta', 'media', 'baja', 'colores duraderos', 'protección UV', 'color permanente']\n",
      "(5):tipo_de_piedra_joyeria:['diamante', 'rubí', 'esmeralda', 'zafiro', 'perla']\n",
      "(5):resistencia_a_las_arrugas:['alta', 'media', 'baja', 'arrugas mínimas', 'resistente a las arrugas']\n",
      "(5):impermeabilidad:['impermeable', 'resistente al agua', 'no impermeable', 'tecnología Gore-Tex', 'tecnología AquaRepel']\n",
      "(5):suavidad:['muy suave', 'suave', 'duro', 'toque aterciopelado', 'textura sedosa']\n",
      "(5):tipo_de_tela:['tejido', 'punto', 'encaje', 'cuero', 'denim']\n",
      "(5):peso:['ligero', 'medio', 'pesado', 'ultraligero', 'ligereza extrema']\n",
      "(4):tipos_de_cintura:['alta', 'media', 'baja', 'fruncida']\n",
      "(4):resistencia_al_agua:['resistente al agua', 'no resistente al agua', 'tejido hidrófugo', 'protección contra la humedad']\n",
      "(4):resistencia_a_las_manchas:['resistente a las manchas', 'no resistente a las manchas', 'manchas invisibles', 'tejido fácil de limpiar']\n",
      "(4):tipo_de_cierre_joyeria:['broche', 'cierre de presión', 'cierre de rosca', 'cierre magnético']\n",
      "(4):tiempo_de_entrega:['entrega inmediata', 'entrega en 24 horas', 'entrega en 3-5 días', 'entrega en 1-2 semanas']\n",
      "(4):resistencia_a_los_rayos_uv:['alta', 'media', 'baja', 'bloqueo de rayos solares']\n",
      "(4):tipo_de_lente_gafas:['polarizadas', 'degradadas', 'espejo', 'transparentes']\n",
      "(4):resistencia_al_viento:['resistente al viento', 'no resistente al viento', 'tejido cortaviento', 'protección contra el viento']\n",
      "(4):tipo_de_asa_bolsos:['asas cortas', 'asas largas', 'correa de hombro', 'correa de cruzar']\n",
      "(4):tipo_de_metal_joyeria:['oro', 'plata', 'platino', 'acero inoxidable']\n",
      "(3):politica_de_devoluciones:['devoluciones gratuitas', 'devoluciones pagadas', 'sin devoluciones']\n",
      "(3):garantia:['garantía de por vida', 'garantía limitada', 'sin garantía']\n",
      "(3):disponibilidad:['en stock', 'agotado', 'pre-pedido']\n",
      "(3):tipo_de_montura_gafas:['completa', 'semi al aire', 'al aire']\n",
      "(3):tipo_de_ajuste_calzado:['ajustado', 'regular', 'amplio']\n",
      "(3):instrucciones_de_cuidado:['lavar a máquina', 'lavar a mano', 'limpiar en seco']\n",
      "(3):tipo_de_ajuste_ropa:['ajustado', 'regular', 'suelto']\n",
      "(2):certificaciones_bienestar_animal:['certificado de bienestar animal', 'sin certificación']\n",
      "(2):opciones_de_personalizacion:['personalizable', 'no personalizable']\n",
      "(2):Marca Nacional:['Si', 'No']\n",
      "(1):local:['X']\n",
      "Total 487 ------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Número de combinaciones distintas no asignadas 487\n",
      "Número de literales/categorías sin asignar 60\n",
      "--------------------------------------------------------------\n",
      "Número total de combinaciones distintas en CSV para categorías asignadas: 417\n",
      "Número total de combinaciones distintas en JSON para categorías asignadas: 417\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar el fichero JSON\n",
    "#with open('./literales_fbc.json', 'r', encoding='utf-8') as f:\n",
    "with open('./literales_ultimate.json', 'r', encoding='utf-8') as f:\n",
    "    category_data = json.load(f)\n",
    "    \n",
    "# Obtener los nombres de las categorías del JSON\n",
    "category_literals_json = set(category_data.keys())\n",
    "\n",
    "print(f\"(json)Número de categorías de literales totales {len(category_literals_json)}\")\n",
    "\n",
    "# Crear una lista para almacenar las combinaciones únicas\n",
    "distinct_combinations = []\n",
    "\n",
    "# Recorrer cada feature_category_id en el JSON\n",
    "total = 0\n",
    "for category_id, values in category_data.items():\n",
    "    # Añadir cada par (feature_category_id, feature_value_id) a la lista\n",
    "    for value_id in values:\n",
    "        total +=1\n",
    "        distinct_combinations.append((category_id, value_id))\n",
    "        #print(f\"({category_id},{value_id}) : {total} vs {len(list(set(distinct_combinations)))}\")\n",
    "#print(f\"\\n(json)Total contadas: {total}\")\n",
    "\n",
    "# Eliminar duplicados convirtiendo la lista a un conjunto, y luego de nuevo a lista\n",
    "distinct_combinations = list(set(distinct_combinations))\n",
    "\n",
    "# Mostrar las combinaciones distintas\n",
    "#print(\"Combinaciones distintas de feature_category_id y feature_value_id:\")\n",
    "#print(distinct_combinations)\n",
    "\n",
    "# Contar el número de combinaciones distintas\n",
    "num_combinations = len(distinct_combinations)\n",
    "print(f\"\\n(json)Número total de combinaciones distintas: {num_combinations}\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "\n",
    "# Cargar el fichero CSV\n",
    "df = pd.read_csv('./item_features_semirelleno_con_literales_actualizado.csv')\n",
    "\n",
    "# Obtener los literales ya asignados en el CSV\n",
    "assigned_literals_csv = set(df['feature_category_literal'].dropna().unique())\n",
    "print(f\"Número de categorías de literales totales asignadas(csv) {len(assigned_literals_csv)}\")\n",
    "\n",
    "# Determinar los literales asignados y no asignados\n",
    "assigned_literals = category_literals_json.intersection(assigned_literals_csv)\n",
    "print(f\"Número de categorías de literales totales asignadas(json) {len(assigned_literals)}\")\n",
    "\n",
    "unassigned_literals = category_literals_json - assigned_literals_csv\n",
    "print(f\"Número de categorías de literales totales sin asignar(json) {len(unassigned_literals)}\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "\n",
    "# Añadir el array de valores posibles para los literales no asignados\n",
    "unassigned_literals_with_values = {literal: category_data[literal] for literal in unassigned_literals}\n",
    "assigned_literals_with_values = {literal: category_data[literal] for literal in assigned_literals}\n",
    "\n",
    "# Ordenar de mayor a menor según el número de elementos en el array de valores\n",
    "unassigned_literals_sorted = dict(sorted(unassigned_literals_with_values.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "assigned_literals_sorted = dict(sorted(assigned_literals_with_values.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------------------\")\n",
    "print(\"Literales asignados con posibles valores, ordenados de mayor a menor por cantidad de valores:\")\n",
    "total = 0\n",
    "for literal, values in assigned_literals_sorted.items():\n",
    "    total += len(values)\n",
    "    print(f\"({len(values)}):{literal}:{values}\")\n",
    "print(f\"Total {total} ------------------------------------------------------------------------------\")\n",
    "\n",
    "# Mostrar los resultados ordenados\n",
    "print(\"Literales no asignados con posibles valores, ordenados de mayor a menor por cantidad de valores:\")\n",
    "total = 0\n",
    "for literal, values in unassigned_literals_sorted.items():\n",
    "    total += len(values)\n",
    "    print(f\"({len(values)}):{literal}:{values}\")\n",
    "print(f\"Total {total} ------------------------------------------------------------------------------\")    \n",
    "\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(f\"Número de combinaciones distintas no asignadas {total}\")\n",
    "#unassigned_literals_with_values_sorted_dict = unassigned_literals_sorted\n",
    "print(f\"Número de literales/categorías sin asignar {len(unassigned_literals_sorted)}\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "\n",
    "# Filtrar las combinaciones distintas en el CSV para las categorías asignadas\n",
    "assigned_combinations_csv = df[df['feature_category_literal'].notna()][['feature_category_id', 'feature_value_id']].drop_duplicates()\n",
    "assigned_combinations_count_csv = assigned_combinations_csv.shape[0]\n",
    "print(f\"Número total de combinaciones distintas en CSV para categorías asignadas: {assigned_combinations_count_csv}\")\n",
    "\n",
    "# Filtrar las combinaciones distintas desde el JSON para las categorías asignadas\n",
    "assigned_combinations_json = [(category_id, value_id) for category_id, values in category_data.items() if category_id in assigned_literals for value_id in values]\n",
    "assigned_combinations_json = list(set(assigned_combinations_json))\n",
    "assigned_combinations_count_json = len(assigned_combinations_json)\n",
    "print(f\"Número total de combinaciones distintas en JSON para categorías asignadas: {assigned_combinations_count_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7a55c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature_category_id feature_category_literal\n",
      "29                     4                  ocasion\n",
      "10                     7          caracteristicas\n",
      "21                    19      pais_de_fabricacion\n",
      "129                   30                  colores\n",
      "17                    32                  generos\n",
      "12                    47               materiales\n",
      "7                     50                    talla\n",
      "25                    55                    marca\n",
      "0                     56         rangos_de_precio\n",
      "8                     61               estaciones\n",
      "2                     68                productos\n",
      "11                    69                 detalles\n",
      "4                     72               estampados\n",
      "Len(x) 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_category_id</th>\n",
       "      <th>feature_category_literal</th>\n",
       "      <th>feature_value_id</th>\n",
       "      <th>feature_value_literal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11812</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>221</td>\n",
       "      <td>Absorbente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23100</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>463</td>\n",
       "      <td>Acolchado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>528</td>\n",
       "      <td>Adaptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>619</td>\n",
       "      <td>Ajustable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>28</td>\n",
       "      <td>Alta tracción</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>2</td>\n",
       "      <td>Amortiguada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>794</td>\n",
       "      <td>Analógico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>298</td>\n",
       "      <td>Antideslizante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369724</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>710</td>\n",
       "      <td>Antiestático</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>492</td>\n",
       "      <td>Comodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>798</td>\n",
       "      <td>Completo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>284</td>\n",
       "      <td>Con borlas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>414</td>\n",
       "      <td>Con flecos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>329</td>\n",
       "      <td>Con refuerzos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>536</td>\n",
       "      <td>Corto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>207</td>\n",
       "      <td>Elástico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7136</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>629</td>\n",
       "      <td>Ergonómico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>170</td>\n",
       "      <td>Flexible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69166</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>364</td>\n",
       "      <td>Ignífugo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>777</td>\n",
       "      <td>Impermeable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>837</td>\n",
       "      <td>Largo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36026</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>652</td>\n",
       "      <td>Lavable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9733</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>836</td>\n",
       "      <td>Liviano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>452</td>\n",
       "      <td>Manga corta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>394</td>\n",
       "      <td>Manga larga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>78</td>\n",
       "      <td>Plana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>490</td>\n",
       "      <td>Plegable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11443</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>315</td>\n",
       "      <td>Reflector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>46</td>\n",
       "      <td>Resistente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46350</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>797</td>\n",
       "      <td>Sin costuras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>276</td>\n",
       "      <td>Tirantes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>838</td>\n",
       "      <td>Translucido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>398</td>\n",
       "      <td>Transpirable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>82</td>\n",
       "      <td>Técnico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113538</th>\n",
       "      <td>7</td>\n",
       "      <td>caracteristicas</td>\n",
       "      <td>244</td>\n",
       "      <td>Térmico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_category_id feature_category_literal  feature_value_id  \\\n",
       "11812                     7          caracteristicas               221   \n",
       "23100                     7          caracteristicas               463   \n",
       "5513                      7          caracteristicas               528   \n",
       "274                       7          caracteristicas               619   \n",
       "1022                      7          caracteristicas                28   \n",
       "675                       7          caracteristicas                 2   \n",
       "313                       7          caracteristicas               794   \n",
       "2624                      7          caracteristicas               298   \n",
       "369724                    7          caracteristicas               710   \n",
       "3104                      7          caracteristicas               492   \n",
       "78                        7          caracteristicas               798   \n",
       "504                       7          caracteristicas               284   \n",
       "183                       7          caracteristicas               414   \n",
       "12117                     7          caracteristicas               329   \n",
       "70                        7          caracteristicas               536   \n",
       "204                       7          caracteristicas               207   \n",
       "7136                      7          caracteristicas               629   \n",
       "4623                      7          caracteristicas               170   \n",
       "69166                     7          caracteristicas               364   \n",
       "4200                      7          caracteristicas               777   \n",
       "46                        7          caracteristicas               837   \n",
       "36026                     7          caracteristicas               652   \n",
       "9733                      7          caracteristicas               836   \n",
       "20                        7          caracteristicas               452   \n",
       "10                        7          caracteristicas               394   \n",
       "2033                      7          caracteristicas                78   \n",
       "496                       7          caracteristicas               490   \n",
       "11443                     7          caracteristicas               315   \n",
       "1975                      7          caracteristicas                46   \n",
       "46350                     7          caracteristicas               797   \n",
       "170                       7          caracteristicas               276   \n",
       "628                       7          caracteristicas               838   \n",
       "596                       7          caracteristicas               398   \n",
       "1885                      7          caracteristicas                82   \n",
       "113538                    7          caracteristicas               244   \n",
       "\n",
       "       feature_value_literal  \n",
       "11812             Absorbente  \n",
       "23100              Acolchado  \n",
       "5513               Adaptable  \n",
       "274                Ajustable  \n",
       "1022           Alta tracción  \n",
       "675              Amortiguada  \n",
       "313                Analógico  \n",
       "2624          Antideslizante  \n",
       "369724          Antiestático  \n",
       "3104                  Comodo  \n",
       "78                  Completo  \n",
       "504               Con borlas  \n",
       "183               Con flecos  \n",
       "12117          Con refuerzos  \n",
       "70                     Corto  \n",
       "204                 Elástico  \n",
       "7136              Ergonómico  \n",
       "4623                Flexible  \n",
       "69166               Ignífugo  \n",
       "4200             Impermeable  \n",
       "46                     Largo  \n",
       "36026                Lavable  \n",
       "9733                 Liviano  \n",
       "20               Manga corta  \n",
       "10               Manga larga  \n",
       "2033                   Plana  \n",
       "496                 Plegable  \n",
       "11443              Reflector  \n",
       "1975              Resistente  \n",
       "46350           Sin costuras  \n",
       "170                 Tirantes  \n",
       "628              Translucido  \n",
       "596             Transpirable  \n",
       "1885                 Técnico  \n",
       "113538               Térmico  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinaciones_categorias_asignadas = df[df['feature_category_literal'].notna()][['feature_category_id','feature_category_literal']].drop_duplicates()\n",
    "combinaciones_categorias_asignadas = combinaciones_categorias_asignadas.sort_values(by=['feature_category_id'])\n",
    "print(combinaciones_categorias_asignadas)\n",
    "\n",
    "combinaciones_asignadas = df[df['feature_category_literal'].notna()][['feature_category_id', 'feature_category_literal','feature_value_id', 'feature_value_literal']].drop_duplicates()\n",
    "\n",
    "# Ordenar por feature_category_id y feature_value_id\n",
    "combinaciones_asignadas_sorted = combinaciones_asignadas.sort_values(by=['feature_category_id', 'feature_value_id'])\n",
    "\n",
    "df2 = combinaciones_asignadas_sorted\n",
    "\n",
    "df_x = df2[df2['feature_category_id']==7]\n",
    "print(f\"Len(x) {len(df_x)}\")\n",
    "\n",
    "#repeated_values = df_x['feature_value_literal'].value_counts()\n",
    "#repeated_values = repeated_values[repeated_values > 1]\n",
    "#repeated_values\n",
    "#valores_determinados = ['450-500'] \n",
    "#resultados = df_x[df_x['feature_value_literal'].isin(valores_determinados)]\n",
    "#resultados\n",
    "\n",
    "df_x.sort_values(by=['feature_value_literal', 'feature_value_literal'])\n",
    "#print(df_x[30:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea57e42",
   "metadata": {},
   "source": [
    "### Hecho, corregido en el fichero -item_features_semirelleno_con_literales_actualizado.csv-, ya no hace falta hacerlo de nuevo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda84158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_literals(df, feature_category_id, feature_value_id, new_category_literal, new_value_literal):\n",
    "    \"\"\"\n",
    "    Actualiza las ocurrencias de feature_category_literal y feature_value_literal en el DataFrame\n",
    "    basadas en los valores proporcionados para feature_category_id y feature_value_id.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame que contiene las columnas a actualizar.\n",
    "    - feature_category_id (str): El valor de feature_category_id para filtrar las filas.\n",
    "    - feature_value_id (str): El valor de feature_value_id para filtrar las filas.\n",
    "    - new_category_literal (str): El nuevo valor para feature_category_literal.\n",
    "    - new_value_literal (str): El nuevo valor para feature_value_literal.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame con los valores actualizados.\n",
    "    \"\"\"\n",
    "    # Asegurarse de que las columnas existen en el DataFrame\n",
    "    required_columns = ['feature_category_id', 'feature_value_id', 'feature_category_literal', 'feature_value_literal']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"El DataFrame debe contener la columna '{col}'\")\n",
    "    \n",
    "    # Convertir los valores de entrada a numéricos si no lo son\n",
    "    feature_category_id = pd.to_numeric(feature_category_id, errors='coerce')\n",
    "    feature_value_id = pd.to_numeric(feature_value_id, errors='coerce')\n",
    "    \n",
    "    # Actualizar los valores en el DataFrame\n",
    "    df.loc[\n",
    "        (df['feature_category_id'] == feature_category_id) & \n",
    "        (df['feature_value_id'] == feature_value_id), \n",
    "        ['feature_category_literal', 'feature_value_literal']\n",
    "    ] = new_category_literal, new_value_literal\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "41b8ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "marcas = ['Zara', 'Mango', 'Massimo Dutti', 'Pull&Bear', 'Bershka', 'Stradivarius', 'Desigual', \n",
    "          'El Ganso', 'Adolfo Domínguez', 'Camper', 'Pikolinos', 'Gioseppo', 'Castañer', \n",
    "          'Panama Jack', 'Mustang', 'Desigual', 'H&M', 'Uniqlo', 'Nike', 'Adidas', 'Puma', \n",
    "          'New Balance', 'Reebok', 'Converse', 'Vans', 'Dr. Martens', 'Timberland', \n",
    "          'Skechers', 'Clarks', 'Crocs', 'Tommy Hilfiger', 'Calvin Klein', 'Ralph Lauren', \n",
    "          \"Levi's\", 'Diesel', 'Guess', 'Michael Kors', 'Coach', 'Fossil', 'Kate Spade', \n",
    "          'Gucci', 'Prada', 'Louis Vuitton', 'Chanel', 'Burberry', 'Balenciaga', 'Valentino', \n",
    "          'Dior', 'Hermès', 'Givenchy', 'Saint Laurent', 'Versace', 'Jimmy Choo', 'Louboutin', \n",
    "          'Alexander McQueen', 'Bottega Veneta', 'Fendi', 'Moschino', 'Kenzo', 'Paul Smith', \n",
    "          'Tory Burch', 'Marc Jacobs', 'Swarovski', 'Armani', 'Max Mara', 'Miu Miu', 'Moncler', \n",
    "          'Salvatore Ferragamo', 'Stella McCartney', 'Thom Browne', \"Tod's\", 'Yves Saint Laurent', \n",
    "          'Zegna', 'Brunello Cucinelli', 'Rag & Bone', 'Acne Studios', 'Isabel Marant', 'Jacquemus', \n",
    "          'Off-White', 'Rick Owens', 'Balmain', 'Emilio Pucci', 'Loewe', 'Missoni', \n",
    "          'Dries Van Noten', 'Margiela', 'Erdem', 'Peter Pilotto', 'Simone Rocha', 'Vetements', \n",
    "          'Virgil Abloh', 'A-Cold-Wall*', 'Alyx', 'Fear of God']\n",
    "\n",
    "# Ordenar la lista alfabéticamente\n",
    "marcas_ordenadas = sorted(marcas)\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='55', \n",
    "    feature_value_id='692', \n",
    "    new_category_literal='marca', \n",
    "    new_value_literal='Givenchy'\n",
    ")\n",
    "\n",
    "marcas_ordenadas\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='69', \n",
    "    feature_value_id='260', \n",
    "    new_category_literal='detalles', \n",
    "    new_value_literal='Cremallera'\n",
    ")\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='436', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='500-550'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='866', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='550-600'\n",
    ")\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='344', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='400-410'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='460', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='410-420'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='523', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='420-430'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='844', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='430-450'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='355', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='350-360'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='400', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='360-370'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='606', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='370-380'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='868', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='380-400'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='194', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='300-310'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='402', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='310-320'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='626', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='320-330'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='843', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='330-350'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='89', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='250-260'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='164', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='260-270'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='503', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='270-280'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='541', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='280-300'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='19', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='200-210'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='23', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='210-220'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='334', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='220-230'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='496', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='230-250'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='29', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='150-160'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='161', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='160-170'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='439', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='170-180'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='589', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='180-200'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='50', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='100-110'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='74', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='110-120'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='332', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='120-130'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='749', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='130-150'\n",
    ")\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='102', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='90-92'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='176', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='92-94'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='192', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='94-96'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='527', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='96-100'\n",
    ")\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='1', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='80-82'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='408', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='82-84'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='792', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='84-86'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='804', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='86-90'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='32', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='70-72'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='131', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='72-74'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='249', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='74-76'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='506', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='76-80'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='231', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='60-62'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='418', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='62-64'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='450', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='64-66'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='501', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='66-70'\n",
    ")\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='239', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='50-52'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='295', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='52-54'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='581', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='54-56'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='757', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='56-60'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='223', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='40-42'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='429', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='42-44'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='594', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='44-46'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='752', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='46-50'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='191', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='30-32'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='427', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='32-34'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='787', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='34-36'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='791', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='36-40'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='39', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='20-22'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='153', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='22-24'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='337', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='24-26'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='741', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='26-30'\n",
    ")\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='312', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='10-12'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='365', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='12-14'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='761', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='14-16'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='56', \n",
    "    feature_value_id='819', \n",
    "    new_category_literal='rangos_de_precio', \n",
    "    new_value_literal='16-20'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='30', \n",
    "    feature_value_id='482', \n",
    "    new_category_literal='colores', \n",
    "    new_value_literal='Púrpura'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='30', \n",
    "    feature_value_id='564', \n",
    "    new_category_literal='colores', \n",
    "    new_value_literal='Beige arena'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='30', \n",
    "    feature_value_id='809', \n",
    "    new_category_literal='colores', \n",
    "    new_value_literal='Turquesa claro'\n",
    ")\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='4', \n",
    "    feature_value_id='331', \n",
    "    new_category_literal='ocasion', \n",
    "    new_value_literal='Eventos Deportivos'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='4', \n",
    "    feature_value_id='385', \n",
    "    new_category_literal='ocasion', \n",
    "    new_value_literal='Cita'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='4', \n",
    "    feature_value_id='635', \n",
    "    new_category_literal='ocasion', \n",
    "    new_value_literal='Gala'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='4', \n",
    "    feature_value_id='865', \n",
    "    new_category_literal='ocasion', \n",
    "    new_value_literal='Temporada Festiva'\n",
    ")\n",
    "\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='7', \n",
    "    feature_value_id='838', \n",
    "    new_category_literal='caracteristicas',\n",
    "    new_value_literal='Translucido'\n",
    ")\n",
    "df = update_literals(\n",
    "    df, \n",
    "    feature_category_id='7', \n",
    "    feature_value_id='710', \n",
    "    new_category_literal='caracteristicas',\n",
    "    new_value_literal='Antiestático'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7363db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame actualizado, si es necesario\n",
    "# el original se saca de -item_features_semirelleno_con_literales.csv-\n",
    "df.to_csv('./item_features_semirelleno_con_literales_actualizado.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdeeb06",
   "metadata": {},
   "source": [
    "### Experimentos para asignar las categorias faltantes, mediante una estrategia avanzada, modelos de IA\n",
    "### (20/ago/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e58ac553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando el DataFrame...\n",
      "Separando datos con y sin valores faltantes...\n",
      "Datos completos: 252104 filas\n",
      "Datos faltantes: 219647 filas\n",
      "Preparando características y objetivos, items con los literales asignados ya!\n",
      "Codificando literales que ya tengo asignados...\n",
      "Dividiendo los datos en conjuntos de entrenamiento y prueba...\n",
      "Entrenando modelo para 'feature_category_literal'...\n",
      "Validación cruzada para 'feature_category_literal': 1.0\n",
      "Entrenando modelo para 'feature_value_literal'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación cruzada para 'feature_value_literal': 0.9999048013347606\n",
      "Preparando datos faltantes para la imputación...\n",
      "Alineando columnas...\n",
      "Imputando valores para 'feature_category_literal'...\n",
      "\n",
      "Asignaciones de 'feature_category_literal' después de la imputación:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asignaciones feature_category_literal:   0%|                                   | 76/471751 [00:00<02:51, 2745.11fila/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 56, Literal: rangos_de_precio\n",
      "ID: 62, Literal: ocasion\n",
      "ID: 68, Literal: productos\n",
      "ID: 33, Literal: ocasion\n",
      "ID: 72, Literal: estampados\n",
      "ID: 29, Literal: materiales\n",
      "ID: 16, Literal: ocasion\n",
      "ID: 50, Literal: talla\n",
      "ID: 61, Literal: estaciones\n",
      "ID: 53, Literal: ocasion\n",
      "ID: 7, Literal: caracteristicas\n",
      "ID: 69, Literal: detalles\n",
      "ID: 47, Literal: materiales\n",
      "ID: 17, Literal: ocasion\n",
      "ID: 32, Literal: generos\n",
      "ID: 11, Literal: ocasion\n",
      "ID: 45, Literal: ocasion\n",
      "ID: 19, Literal: pais_de_fabricacion\n",
      "ID: 46, Literal: ocasion\n",
      "ID: 73, Literal: ocasion\n",
      "ID: 55, Literal: marca\n",
      "ID: 63, Literal: ocasion\n",
      "ID: 59, Literal: ocasion\n",
      "ID: 4, Literal: ocasion\n",
      "ID: 5, Literal: ocasion\n",
      "ID: 26, Literal: ocasion\n",
      "ID: 3, Literal: ocasion\n",
      "ID: 65, Literal: ocasion\n",
      "ID: 18, Literal: ocasion\n",
      "ID: 22, Literal: ocasion\n",
      "ID: 41, Literal: ocasion\n",
      "ID: 15, Literal: ocasion\n",
      "ID: 44, Literal: ocasion\n",
      "ID: 34, Literal: ocasion\n",
      "ID: 12, Literal: ocasion\n",
      "ID: 30, Literal: colores\n",
      "ID: 21, Literal: ocasion\n",
      "ID: 24, Literal: ocasion\n",
      "ID: 28, Literal: ocasion\n",
      "ID: 14, Literal: ocasion\n",
      "ID: 8, Literal: ocasion\n",
      "ID: 70, Literal: ocasion\n",
      "ID: 57, Literal: ocasion\n",
      "ID: 25, Literal: ocasion\n",
      "ID: 51, Literal: ocasion\n",
      "ID: 49, Literal: ocasion\n",
      "ID: 38, Literal: ocasion\n",
      "ID: 31, Literal: ocasion\n",
      "ID: 37, Literal: ocasion\n",
      "ID: 42, Literal: ocasion\n",
      "ID: 36, Literal: ocasion\n",
      "ID: 67, Literal: ocasion\n",
      "ID: 39, Literal: ocasion\n",
      "ID: 23, Literal: ocasion\n",
      "ID: 2, Literal: ocasion\n",
      "ID: 60, Literal: ocasion\n",
      "ID: 6, Literal: ocasion\n",
      "ID: 48, Literal: ocasion\n",
      "ID: 1, Literal: ocasion\n",
      "ID: 58, Literal: ocasion\n",
      "ID: 52, Literal: ocasion\n",
      "ID: 35, Literal: ocasion\n",
      "ID: 43, Literal: ocasion\n",
      "ID: 10, Literal: ocasion\n",
      "ID: 54, Literal: ocasion\n",
      "ID: 29, Literal: ocasion\n",
      "ID: 33, Literal: materiales\n",
      "ID: 64, Literal: ocasion\n",
      "ID: 71, Literal: ocasion\n",
      "ID: 20, Literal: ocasion\n",
      "ID: 66, Literal: ocasion\n",
      "ID: 40, Literal: ocasion\n",
      "ID: 9, Literal: ocasion\n",
      "ID: 13, Literal: ocasion\n",
      "ID: 44, Literal: rangos_de_precio\n",
      "ID: 27, Literal: ocasion\n",
      "Validando literales en 'feature_category_literal'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validando feature_category_literal: 100%|██████████████████████████████████████| 73/73 [00:00<00:00, 111.39categoría/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando el DataFrame imputado en 'articulos_completados_modelo.csv'...\n",
      "Imputación completada y guardada en 'articulos_completados_modelo.csv'\n"
     ]
    }
   ],
   "source": [
    "# (0) Experimento inicial \n",
    "\n",
    "# Resultado :: EL problema de esta solución, es que siempre recomienda el mismo literal a la categoría faltante!\n",
    "# Verificación del Modelo de Imputación: Asegúrate de que el modelo de RandomForest está correctamente entrenado y validado. \n",
    "# Si el modelo está sobreajustado o no tiene suficiente variabilidad en los datos de entrenamiento, podría estar produciendo \n",
    "# resultados repetitivos.\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configurar tqdm para que se muestre una barra de progreso en las llamadas a pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Cargar el fichero CSV\n",
    "df = pd.read_csv('./item_features_semirelleno_con_literales_actualizado.csv')\n",
    "\n",
    "# Cargar el fichero JSON\n",
    "with open('./literales_ultimate.json', 'r', encoding='utf-8') as f:\n",
    "    category_data = json.load(f)\n",
    "\n",
    "# Preparar el DataFrame\n",
    "print(\"Preparando el DataFrame...\")\n",
    "df['feature_category_id'] = df['feature_category_id'].astype('category')\n",
    "df['feature_value_id'] = df['feature_value_id'].astype('category')\n",
    "df['feature_category_literal'] = df['feature_category_literal'].astype('category')\n",
    "df['feature_value_literal'] = df['feature_value_literal'].astype('category')\n",
    "\n",
    "# Convertir JSON a DataFrame\n",
    "category_literals = {category: set(literals) for category, literals in category_data.items()}\n",
    "\n",
    "# Separar datos con y sin valores faltantes\n",
    "print(\"Separando datos con y sin valores faltantes...\")\n",
    "data_with_values = df.dropna(subset=['feature_category_literal', 'feature_value_literal'])\n",
    "data_missing_values = df[df['feature_category_literal'].isna() | df['feature_value_literal'].isna()]\n",
    "\n",
    "print(f\"Datos completos: {data_with_values.shape[0]} filas\")\n",
    "print(f\"Datos faltantes: {data_missing_values.shape[0]} filas\")\n",
    "\n",
    "# Características y objetivos, items con literales asignados!\n",
    "print(\"Preparando características y objetivos, items con los literales asignados ya!\")\n",
    "X_with_values = pd.get_dummies(data_with_values[['feature_category_id', 'feature_value_id']])\n",
    "y_category_literal = data_with_values['feature_category_literal']\n",
    "y_value_literal = data_with_values['feature_value_literal']\n",
    "\n",
    "# Codificar literales\n",
    "print(\"Codificando literales que ya tengo asignados...\")\n",
    "encoder_category_literal = LabelEncoder()\n",
    "encoder_value_literal = LabelEncoder()\n",
    "\n",
    "y_category_literal_encoded = encoder_category_literal.fit_transform(y_category_literal)\n",
    "y_value_literal_encoded = encoder_value_literal.fit_transform(y_value_literal)\n",
    "\n",
    "# Dividir el conjunto de datos\n",
    "print(\"Dividiendo los datos en conjuntos de entrenamiento y prueba...\")\n",
    "X_train, X_test, y_train_category, y_test_category = train_test_split(X_with_values, y_category_literal_encoded, test_size=0.2, random_state=42)\n",
    "X_train_value, X_test_value, y_train_value, y_test_value = train_test_split(X_with_values, y_value_literal_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelos con validación cruzada\n",
    "print(\"Entrenando modelo para 'feature_category_literal'...\")\n",
    "model_category_literal = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_category_literal.fit(X_train, y_train_category)\n",
    "cv_scores_category = cross_val_score(model_category_literal, X_with_values, y_category_literal_encoded, cv=5)\n",
    "print(f\"Validación cruzada para 'feature_category_literal': {cv_scores_category.mean()}\")\n",
    "\n",
    "#print(\"Entrenando modelo para 'feature_value_literal'...\")\n",
    "#model_value_literal = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "#model_value_literal.fit(X_train_value, y_train_value)\n",
    "#cv_scores_value = cross_val_score(model_value_literal, X_with_values, y_value_literal_encoded, cv=5)\n",
    "#print(f\"Validación cruzada para 'feature_value_literal': {cv_scores_value.mean()}\")\n",
    "\n",
    "# Preparar los datos faltantes para la imputación\n",
    "print(\"Preparando datos faltantes para la imputación...\")\n",
    "X_missing = pd.get_dummies(df.loc[df['feature_category_literal'].isna() | df['feature_value_literal'].isna(), ['feature_category_id', 'feature_value_id']])\n",
    "\n",
    "# Asegurarse de que las columnas están alineadas entre el conjunto de datos de entrenamiento y los datos faltantes\n",
    "print(\"Alineando columnas...\")\n",
    "missing_cols = set(X_with_values.columns) - set(X_missing.columns)\n",
    "for col in missing_cols:\n",
    "    X_missing[col] = 0\n",
    "X_missing = X_missing[X_with_values.columns]\n",
    "\n",
    "# Imputar valores para feature_category_literal\n",
    "print(\"Imputando valores para 'feature_category_literal'...\")\n",
    "predicted_category_literals = model_category_literal.predict(X_missing)\n",
    "df.loc[df['feature_category_literal'].isna(), 'feature_category_literal'] = encoder_category_literal.inverse_transform(predicted_category_literals)\n",
    "\n",
    "# Mostrar asignaciones después de la imputación\n",
    "print(\"\\nAsignaciones de 'feature_category_literal' después de la imputación:\")\n",
    "for idx, row in tqdm(df[df['feature_category_literal'].notna()][['feature_category_id', 'feature_category_literal']].drop_duplicates().iterrows(), total=df.shape[0], desc=\"Asignaciones feature_category_literal\", unit=\"fila\"):\n",
    "    print(f\"ID: {row['feature_category_id']}, Literal: {row['feature_category_literal']}\")\n",
    "\n",
    "# Imputar valores para feature_value_literal\n",
    "#print(\"Imputando valores para 'feature_value_literal'...\")\n",
    "#predicted_value_literals = model_value_literal.predict(X_missing)\n",
    "#df.loc[df['feature_value_literal'].isna(), 'feature_value_literal'] = encoder_value_literal.inverse_transform(predicted_value_literals)\n",
    "\n",
    "# Mostrar asignaciones después de la imputación\n",
    "#print(\"\\nAsignaciones de 'feature_value_literal' después de la imputación:\")\n",
    "#for idx, row in tqdm(df[df['feature_value_literal'].notna()][['feature_value_id', 'feature_value_literal']].drop_duplicates().iterrows(), total=df.shape[0], desc=\"Asignaciones feature_value_literal\", unit=\"fila\"):\n",
    "#    print(f\"ID: {row['feature_value_id']}, Literal: {row['feature_value_literal']}\")\n",
    "\n",
    "# Verificar que los literales imputados están en el JSON\n",
    "def validate_literals(df, column, literals_dict):\n",
    "    print(f\"Validando literales en '{column}'...\")\n",
    "    for category, literals in tqdm(literals_dict.items(), desc=f\"Validando {column}\", unit=\"categoría\"):\n",
    "        df.loc[df['feature_category_id'] == category, column] = df[column].apply(\n",
    "            lambda x: x if x in literals else 'Desconocido'\n",
    "        )\n",
    "\n",
    "# Aplicar validación para feature_category_literal\n",
    "validate_literals(df, 'feature_category_literal', category_literals)\n",
    "\n",
    "# Aplicar validación para feature_value_literal\n",
    "#validate_literals(df, 'feature_value_literal', category_literals)\n",
    "\n",
    "# Guardar el CSV con los valores imputados\n",
    "print(\"Guardando el DataFrame imputado en 'articulos_completados_modelo.csv'...\")\n",
    "df.to_csv('./item_features_ya_relleno_con_literales.csv', index=False)\n",
    "\n",
    "print(\"Imputación completada y guardada en 'articulos_completados_modelo.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Predicción con Restricción de Unicidad Usando RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "# Cargar el fichero CSV\n",
    "df = pd.read_csv('./item_features_semirelleno_con_literales_actualizado.csv')\n",
    "\n",
    "# Cargar el fichero JSON\n",
    "with open('./literales_ultimate.json', 'r', encoding='utf-8') as f:\n",
    "    category_data = json.load(f)\n",
    "\n",
    "# Convertir las columnas categóricas a texto temporalmente para evitar errores\n",
    "df['feature_category_literal'] = df['feature_category_literal'].astype(str)\n",
    "df['feature_value_literal'] = df['feature_value_literal'].astype(str)\n",
    "\n",
    "# Preprocesar datos\n",
    "def prepare_data(df, category_data):\n",
    "    # Extraer literales de categorías y valores\n",
    "    categories = list(category_data.keys())\n",
    "    category_literals = {cat: literal for cat, literals in category_data.items() for literal in literals}\n",
    "    \n",
    "    # Crear mapeos para los literales y IDs\n",
    "    category_id_to_literal = {i: cat for cat, i in enumerate(categories)}\n",
    "    literal_to_id = {v: k for k, v in category_id_to_literal.items()}\n",
    "    \n",
    "    # Filtrar datos con valores no faltantes\n",
    "    data_with_values = df.dropna(subset=['feature_category_literal', 'feature_value_literal'])\n",
    "    data_missing_values = df[df['feature_category_literal'].isna() | df['feature_value_literal'].isna()]\n",
    "\n",
    "    return data_with_values, data_missing_values, category_literals, category_id_to_literal, literal_to_id\n",
    "\n",
    "# Crear modelos y transformadores\n",
    "def create_model():\n",
    "    return make_pipeline(\n",
    "        ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore'), ['feature_category_id', 'feature_value_id'])\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        ),\n",
    "        SimpleImputer(strategy='most_frequent'),\n",
    "        RandomForestClassifier()\n",
    "    )\n",
    "\n",
    "def predict_with_unique_constraint(model, X_missing, encoder, assigned):\n",
    "    # Verificar si X_missing está vacío\n",
    "    if X_missing.empty:\n",
    "        print(\"X_missing está vacío.\")\n",
    "        return np.array([])\n",
    "    \n",
    "    # Predicción con restricciones de unicidad\n",
    "    predictions = model.predict(X_missing)\n",
    "    predicted_values = encoder.inverse_transform(predictions)\n",
    "    for i, value in enumerate(predicted_values):\n",
    "        if value in assigned:\n",
    "            predictions[i] = -1  # Marcar como no válido si ya asignado\n",
    "    return encoder.inverse_transform(predictions)\n",
    "\n",
    "# Preparar datos\n",
    "data_with_values, data_missing_values, category_literals, category_id_to_literal, literal_to_id = prepare_data(df, category_data)\n",
    "\n",
    "# Crear y ajustar modelos\n",
    "model_category_literal = create_model()\n",
    "model_value_literal = create_model()\n",
    "\n",
    "# Entrenar modelos (esto es solo un ejemplo; usa tus datos de entrenamiento)\n",
    "X_with_values = data_with_values[['feature_category_id', 'feature_value_id']]\n",
    "y_category = data_with_values['feature_category_literal']\n",
    "y_value = data_with_values['feature_value_literal']\n",
    "model_category_literal.fit(X_with_values, y_category)\n",
    "model_value_literal.fit(X_with_values, y_value)\n",
    "\n",
    "# Preparar para predicción\n",
    "X_missing = df[df['feature_category_literal'].isna() | df['feature_value_literal'].isna()][['feature_category_id', 'feature_value_id']]\n",
    "assigned_categories = set(data_with_values['feature_category_literal'])\n",
    "assigned_values = set(data_with_values['feature_value_literal'])\n",
    "\n",
    "# Verificar si hay datos faltantes para imputar\n",
    "if X_missing.empty:\n",
    "    print(\"No hay datos faltantes para imputar.\")\n",
    "else:\n",
    "    # Imputar valores faltantes\n",
    "    df.loc[df['feature_category_literal'].isna(), 'feature_category_literal'] = predict_with_unique_constraint(model_category_literal, X_missing, category_id_to_literal, assigned_categories)\n",
    "    df.loc[df['feature_value_literal'].isna(), 'feature_value_literal'] = predict_with_unique_constraint(model_value_literal, X_missing, literal_to_id, assigned_values)\n",
    "\n",
    "# Guardar resultados\n",
    "df.to_csv('./item_features_ya_relleno_con_literales.csv', index=False)\n",
    "print(\"Asignaciones completadas y guardadas en './item_features_ya_relleno_con_literales.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58fc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Predicción con Múltiples Candidatos y Validación\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cargar el fichero CSV\n",
    "df = pd.read_csv('./item_features_semirelleno_con_literales_actualizado.csv')\n",
    "\n",
    "# Cargar el fichero JSON\n",
    "with open('./literales_ultimate.json', 'r', encoding='utf-8') as f:\n",
    "    category_data = json.load(f)\n",
    "\n",
    "# Preparar el DataFrame\n",
    "df['feature_category_id'] = df['feature_category_id'].astype('category')\n",
    "df['feature_value_id'] = df['feature_value_id'].astype('category')\n",
    "df['feature_category_literal'] = df['feature_category_literal'].astype('category')\n",
    "df['feature_value_literal'] = df['feature_value_literal'].astype('category')\n",
    "\n",
    "# Preparar los datos para la imputación\n",
    "data_with_values = df.dropna(subset=['feature_category_literal', 'feature_value_literal'])\n",
    "data_missing_values = df[df['feature_category_literal'].isna() | df['feature_value_literal'].isna()]\n",
    "\n",
    "X_with_values = pd.get_dummies(data_with_values[['feature_category_id', 'feature_value_id']])\n",
    "y_category_literal = data_with_values['feature_category_literal']\n",
    "y_value_literal = data_with_values['feature_value_literal']\n",
    "\n",
    "encoder_category_literal = LabelEncoder()\n",
    "encoder_value_literal = LabelEncoder()\n",
    "\n",
    "y_category_literal_encoded = encoder_category_literal.fit_transform(y_category_literal)\n",
    "y_value_literal_encoded = encoder_value_literal.fit_transform(y_value_literal)\n",
    "\n",
    "# Entrenar modelos\n",
    "model_category_literal = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_category_literal.fit(X_with_values, y_category_literal_encoded)\n",
    "\n",
    "model_value_literal = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_value_literal.fit(X_with_values, y_value_literal_encoded)\n",
    "\n",
    "# Predicción con múltiples candidatos\n",
    "def predict_multiple_candidates(model, X, encoder, n_candidates=5):\n",
    "    probs = model.predict_proba(X)\n",
    "    top_candidates = probs.argsort(axis=1)[:, -n_candidates:]  # n_candidates candidates\n",
    "    decoded_candidates = []\n",
    "    for idx, candidates in enumerate(top_candidates):\n",
    "        decoded_values = encoder.inverse_transform(candidates)\n",
    "        decoded_candidates.append(decoded_values)\n",
    "    return decoded_candidates\n",
    "\n",
    "# Imputar valores\n",
    "X_missing = pd.get_dummies(df[df['feature_category_literal'].isna() | df['feature_value_literal'].isna()][['feature_category_id', 'feature_value_id']])\n",
    "missing_cols = set(X_with_values.columns) - set(X_missing.columns)\n",
    "for col in missing_cols:\n",
    "    X_missing[col] = 0\n",
    "X_missing = X_missing[X_with_values.columns]\n",
    "\n",
    "# Imputar feature_category_literal\n",
    "candidates_category_literals = predict_multiple_candidates(model_category_literal, X_missing, encoder_category_literal)\n",
    "for i, (index, row) in enumerate(df[df['feature_category_literal'].isna()].iterrows()):\n",
    "    for candidate in candidates_category_literals[i]:\n",
    "        if candidate not in df['feature_category_literal'].values:\n",
    "            df.at[index, 'feature_category_literal'] = candidate\n",
    "            break\n",
    "\n",
    "# Imputar feature_value_literal\n",
    "candidates_value_literals = predict_multiple_candidates(model_value_literal, X_missing, encoder_value_literal)\n",
    "for i, (index, row) in enumerate(df[df['feature_value_literal'].isna()].iterrows()):\n",
    "    for candidate in candidates_value_literals[i]:\n",
    "        if candidate not in df['feature_value_literal'].values:\n",
    "            df.at[index, 'feature_value_literal'] = candidate\n",
    "            break\n",
    "\n",
    "df.to_csv('./item_features_ya_relleno_con_literales2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b0ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) Optimización de Imputación Usando Programación Matemática\n",
    "import pandas as pd\n",
    "import json\n",
    "from ortools.linear_solver import pywraplp\n",
    "\n",
    "# Cargar el fichero CSV\n",
    "df = pd.read_csv('./item_features_semirelleno_con_literales.csv')\n",
    "\n",
    "# Cargar el fichero JSON\n",
    "with open('./literales.json', 'r', encoding='utf-8') as f:\n",
    "    category_data = json.load(f)\n",
    "\n",
    "# Preprocesar datos\n",
    "def prepare_data(df, category_data):\n",
    "    # Extraer literales de categorías y valores\n",
    "    categories = list(category_data.keys())\n",
    "    category_literals = {cat: literal for cat, literals in category_data.items() for literal in literals}\n",
    "    \n",
    "    # Crear mapeos para los literales y IDs\n",
    "    category_id_to_literal = {i: cat for cat, i in enumerate(categories)}\n",
    "    literal_to_id = {v: k for k, v in category_id_to_literal.items()}\n",
    "    \n",
    "    # Filtrar datos con valores no faltantes\n",
    "    data_with_values = df.dropna(subset=['feature_category_literal', 'feature_value_literal'])\n",
    "    data_missing_values = df[df['feature_category_literal'].isna() | df['feature_value_literal'].isna()]\n",
    "\n",
    "    return data_with_values, data_missing_values, category_literals, category_id_to_literal, literal_to_id\n",
    "\n",
    "def optimize_assignments(candidates, literals_to_assign):\n",
    "    solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "    num_items = len(candidates)\n",
    "    num_literals = len(literals_to_assign)\n",
    "\n",
    "    # Variables de decisión: x[i, j] = 1 si la categoría i se asigna al literal j\n",
    "    x = {}\n",
    "    for i in range(num_items):\n",
    "        for j in range(num_literals):\n",
    "            x[i, j] = solver.BoolVar(f'x[{i},{j}]')\n",
    "    \n",
    "    # Restricción: cada ítem debe ser asignado exactamente una vez\n",
    "    for i in range(num_items):\n",
    "        solver.Add(sum(x[i, j] for j in range(num_literals)) == 1)\n",
    "\n",
    "    # Restricción: cada literal debe ser asignado a un solo ítem\n",
    "    for j in range(num_literals):\n",
    "        solver.Add(sum(x[i, j] for i in range(num_items)) <= 1)\n",
    "\n",
    "    # Objetivo: No es necesario un objetivo específico, solo resolver el problema\n",
    "    solver.Minimize(0)\n",
    "    \n",
    "    # Resolver\n",
    "    status = solver.Solve()\n",
    "    \n",
    "    if status == pywraplp.Solver.OPTIMAL:\n",
    "        assignment = {}\n",
    "        for i in range(num_items):\n",
    "            for j in range(num_literals):\n",
    "                if x[i, j].solution_value() == 1:\n",
    "                    assignment[i] = j\n",
    "        return assignment\n",
    "    else:\n",
    "        print('No se encontró una solución óptima.')\n",
    "        return None\n",
    "\n",
    "# Preparar datos\n",
    "data_with_values, data_missing_values, category_literals, category_id_to_literal, literal_to_id = prepare_data(df, category_data)\n",
    "\n",
    "# Crear lista de candidatos y literales\n",
    "candidates = data_missing_values.index.tolist()\n",
    "literals_to_assign = list(set(category_id_to_literal.values()) - set(data_with_values['feature_category_literal'].unique()))\n",
    "\n",
    "# Asignar literales\n",
    "assignment = optimize_assignments(candidates, literals_to_assign)\n",
    "\n",
    "# Aplicar asignaciones a los datos faltantes\n",
    "if assignment:\n",
    "    for idx, literal_idx in assignment.items():\n",
    "        literal = literals_to_assign[literal_idx]\n",
    "        df.at[candidates[idx], 'feature_category_literal'] = literal\n",
    "\n",
    "df.to_csv('./item_features_ya_relleno_con_literales3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
