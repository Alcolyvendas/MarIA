{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e03e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este mensaje se verá en la consola.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "class PrintToFile:\n",
    "    def __init__(self, file_name=None):\n",
    "        if file_name is None:\n",
    "            file_name = self.get_notebook_name() + \".txt\"\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def get_notebook_name(self):\n",
    "       \n",
    "        return \"encoderDecoder_MLP_redNeuronalProfunda\"\n",
    "\n",
    "    def print(self, *args, **kwargs):\n",
    "        fecha_hora = datetime.now().strftime(\"[%d/%m/%Y %H:%M:%S]\")\n",
    "        mensaje = fecha_hora + \" \" + \" \".join(map(str, args))\n",
    "\n",
    "        with open(self.file_name, \"a\") as f:\n",
    "            original_stdout = sys.stdout\n",
    "            sys.stdout = f\n",
    "\n",
    "            try:\n",
    "                print(mensaje, **kwargs)\n",
    "            finally:\n",
    "                sys.stdout = original_stdout\n",
    "\n",
    "    def reprint(self, *args, **kwargs):\n",
    "        self.print(*args, **kwargs)\n",
    "        print(*args, **kwargs)\n",
    "\n",
    "# Crear una instancia de la clase PrintToFile\n",
    "p2f = PrintToFile()\n",
    "\n",
    "# Imprimir en el archivo usando la función print de la clase\n",
    "p2f.print(\"Este es un mensaje.\")\n",
    "p2f.print(\"Otro mensaje más.\")\n",
    "\n",
    "# Continuar imprimiendo normalmente en la consola\n",
    "print(\"Este mensaje se verá en la consola.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd12470",
   "metadata": {},
   "source": [
    "Explicación de Cada Modelo\n",
    "\n",
    "    MLPClassifier: Un modelo de red neuronal que puede capturar relaciones no lineales en los datos. Es adecuado para problemas con datos tabulares.\n",
    "\n",
    "    XGBoost: Un modelo de boosting basado en árboles que maneja bien datos tabulares y puede capturar interacciones complejas entre características.\n",
    "\n",
    "    CatBoost: Un modelo de boosting que maneja de manera eficiente características categóricas y puede ser más rápido de entrenar en comparación con XGBoost.\n",
    "\n",
    "Consideraciones Adicionales\n",
    "\n",
    "    Preprocesamiento de Datos: Asegúrate de que el preprocesamiento (como la codificación de características categóricas) sea consistente para todos los modelos.\n",
    "\n",
    "    Ajuste de Hiperparámetros: Puedes ajustar los hiperparámetros de los modelos para mejorar el rendimiento, utilizando técnicas como la búsqueda en cuadrícula o la optimización bayesiana.\n",
    "\n",
    "    Validación Cruzada: Utiliza validación cruzada para evaluar el rendimiento del modelo y evitar el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af08437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05 seg.s\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class TimeTracker:\n",
    "    def __init__(self, start_time = None):\n",
    "        \"\"\"\n",
    "        Inicializa el objeto TimeTracker con el tiempo de inicio actual.\n",
    "        \"\"\"\n",
    "        if start_time == None:\n",
    "            self.start_time = datetime.now()\n",
    "        else:\n",
    "            self.start_time = start_time \n",
    "    \n",
    "    def dime_que_llevo(self, current_time = None):\n",
    "        \"\"\"\n",
    "        Calcula la diferencia de tiempo desde el inicio y la devuelve formateada en horas, minutos y segundos.\n",
    "        \n",
    "        Returns:\n",
    "            str: La diferencia de tiempo formateada como 'HH:MM:SS'.\n",
    "        \"\"\"\n",
    "        # Obtiene el tiempo actual\n",
    "        if (current_time == None):\n",
    "            current_time = datetime.now()\n",
    "        \n",
    "        # Calcula la diferencia de tiempo entre el tiempo actual y el tiempo de inicio\n",
    "        time_difference = current_time - self.start_time\n",
    "\n",
    "        # Extrae los segundos totales de la diferencia\n",
    "        total_seconds = int(time_difference.total_seconds())\n",
    "\n",
    "        # Calcula horas, minutos y segundos\n",
    "        hours = total_seconds // 3600\n",
    "        minutes = (total_seconds % 3600) // 60\n",
    "        seconds = total_seconds % 60\n",
    "\n",
    "        # Formatea la diferencia como HH:MM:SS\n",
    "        formatted_difference = f\"{seconds:02} seg.s\"\n",
    "        if (minutes > 0):\n",
    "            formatted_difference = f\"{minutes:02} min.s y {formatted_difference}\"\n",
    "        if (hours > 0):\n",
    "            formatted_difference = f\"{hours:02} horas {formatted_difference}\" \n",
    "            \n",
    "        self.start_time = datetime.now()\n",
    "        \n",
    "        return formatted_difference\n",
    "\n",
    "# Ejemplo de uso\n",
    "tracker = TimeTracker()\n",
    "# Simulación de esperar algún tiempo\n",
    "import time\n",
    "time.sleep(5)  # Espera 5 segundos para demostrar el cálculo\n",
    "p2f.reprint(tracker.dime_que_llevo())  # Salida: '00:00:05'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "528d432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos preparados para el modelo MLPClassifier...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Paso 0: Cargar el fichero CSV y el JSON con los literales de categorías\n",
    "#df = pd.read_csv('./item_features_semirelleno_con_literales_actualizado.csv')\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP.csv')\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP_2.csv')\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP_3.csv')\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP_4.csv')\n",
    "# El 5 fue asociando por la longitud de los valores únicos\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP_6.csv')\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP_7.csv')\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP_8.csv')\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP_9.csv')\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP_10.csv')\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP_11.csv')\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP_12.csv')\n",
    "# El 13 fue asociando por la longitud de los valores únicos\n",
    "#df = pd.read_csv('./item_features_rellenado_con_literales_MLP_13.csv')\n",
    "df = pd.read_csv('./item_features_rellenado_con_literales_MLP_14_con_values_id.csv')\n",
    "\n",
    "with open('./literales_ultimate.json', 'r', encoding='utf-8') as f:\n",
    "    category_data = json.load(f)\n",
    "\n",
    "# Contar los valores distintos de feature_value_id por cada feature_category_id\n",
    "category_value_counts = df.groupby('feature_category_id')['feature_value_id'].nunique()\n",
    "\n",
    "# Filtrar las categorías en category_data para que coincidan con los conteos de feature_value_id\n",
    "filtered_category_data = {}\n",
    "for category_literal, values in category_data.items():\n",
    "    for feature_category_id, count in category_value_counts.items():\n",
    "        if len(values) == count:\n",
    "            filtered_category_data[category_literal] = values\n",
    "\n",
    "# Convertir las claves de filtered_category_data a una lista\n",
    "category_literals = list(filtered_category_data.keys())\n",
    "\n",
    "# Identificar categorías válidas que no están en feature_category_literal del DataFrame\n",
    "df_category_literals = df['feature_category_literal'].unique()\n",
    "missing_categories = set(category_literals) - set(df_category_literals)\n",
    "\n",
    "# Codificar todos los literales posibles desde el fichero JSON\n",
    "encoder_category_literal = LabelEncoder()\n",
    "encoder_category_literal.fit(category_literals)\n",
    "\n",
    "# Separar el DataFrame en dos: uno con valores completos y otro con valores faltantes\n",
    "df['filled_literal'] = df['feature_category_literal'].isin(category_literals)\n",
    "\n",
    "\n",
    "# Para los datos completos\n",
    "#df_complete['feature_category_literal_encoded'] = encoder_category_literal.transform(df_complete['feature_category_literal'])\n",
    "def safe_transform(row):\n",
    "    \"\"\"\n",
    "    Transforma la categoría si 'filled_literal' es True.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): Fila del DataFrame que contiene las columnas 'feature_category_literal' y 'filled_literal'.\n",
    "        \n",
    "    Returns:\n",
    "        Transformed value if 'filled_literal' is True, else None.\n",
    "    \"\"\"\n",
    "    if row['filled_literal']:  # Verifica el valor de 'filled_literal'\n",
    "        try:\n",
    "            return encoder_category_literal.transform([row['feature_category_literal']])[0]\n",
    "        except ValueError:\n",
    "            return None  # O un valor que consideres adecuado si la categoría no se encuentra en el encoder\n",
    "    else:\n",
    "        return None  # O un valor que consideres adecuado para entradas vacías\n",
    "\n",
    "# Aplicar la función safe_transform a cada fila en el DataFrame\n",
    "#df_complete['feature_category_literal_encoded'] = df_complete.apply(safe_transform, axis=1)\n",
    "df['feature_category_literal_encoded'] = df.apply(safe_transform, axis=1)\n",
    "\n",
    "df_complete = df[df['filled_literal']]\n",
    "df_missing = df[~df['filled_literal']]\n",
    "\n",
    "# Opcional: Eliminar la columna auxiliar si ya no se necesita\n",
    "df = df.drop(columns=['filled_literal'])\n",
    "df_missing = df_missing.drop(columns=['filled_literal'])\n",
    "df_complete = df_complete.drop(columns=['filled_literal'])\n",
    "\n",
    "# Definir X y y para el modelo\n",
    "X = pd.get_dummies(df_complete[['feature_category_id']])\n",
    "y = df_complete['feature_category_literal_encoded']\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "p2f.reprint(\"Datos preparados para el modelo MLPClassifier...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59afc990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo MLPClassifier...\n",
      "Iteration 1, loss = 2.45892292\n",
      "Validation score: 0.493677\n",
      "Iteration 2, loss = 1.67929428\n",
      "Validation score: 0.604693\n",
      "Iteration 3, loss = 1.39610196\n",
      "Validation score: 0.546356\n",
      "Iteration 4, loss = 1.22202235\n",
      "Validation score: 0.665454\n",
      "Iteration 5, loss = 1.10585095\n",
      "Validation score: 0.688846\n",
      "Iteration 6, loss = 1.02009941\n",
      "Validation score: 0.737246\n",
      "Iteration 7, loss = 0.95077019\n",
      "Validation score: 0.813460\n",
      "Iteration 8, loss = 0.89117732\n",
      "Validation score: 0.813460\n",
      "Iteration 9, loss = 0.83868405\n",
      "Validation score: 0.771003\n",
      "Iteration 10, loss = 0.79234411\n",
      "Validation score: 0.765155\n",
      "Iteration 11, loss = 0.75000540\n",
      "Validation score: 0.792992\n",
      "Iteration 12, loss = 0.70973588\n",
      "Validation score: 0.844292\n",
      "Iteration 13, loss = 0.67332991\n",
      "Validation score: 0.796724\n",
      "Iteration 14, loss = 0.64120860\n",
      "Validation score: 0.844292\n",
      "Iteration 15, loss = 0.61198053\n",
      "Validation score: 0.844292\n",
      "Iteration 16, loss = 0.58377126\n",
      "Validation score: 0.854633\n",
      "Iteration 17, loss = 0.55899085\n",
      "Validation score: 0.818880\n",
      "Iteration 18, loss = 0.53577335\n",
      "Validation score: 0.844649\n",
      "Iteration 19, loss = 0.51311299\n",
      "Validation score: 0.884776\n",
      "Iteration 20, loss = 0.49241082\n",
      "Validation score: 0.861337\n",
      "Iteration 21, loss = 0.47472692\n",
      "Validation score: 0.873080\n",
      "Iteration 22, loss = 0.45586161\n",
      "Validation score: 0.866329\n",
      "Iteration 23, loss = 0.43927617\n",
      "Validation score: 0.889578\n",
      "Iteration 24, loss = 0.42302611\n",
      "Validation score: 0.894570\n",
      "Iteration 25, loss = 0.41528942\n",
      "Validation score: 0.911853\n",
      "Iteration 26, loss = 0.39475618\n",
      "Validation score: 0.915086\n",
      "Iteration 27, loss = 0.38176627\n",
      "Validation score: 0.903461\n",
      "Iteration 28, loss = 0.36836962\n",
      "Validation score: 0.913778\n",
      "Iteration 29, loss = 0.35520877\n",
      "Validation score: 0.920744\n",
      "Iteration 30, loss = 0.34404668\n",
      "Validation score: 0.922812\n",
      "Iteration 31, loss = 0.33135669\n",
      "Validation score: 0.916560\n",
      "Iteration 32, loss = 0.32022319\n",
      "Validation score: 0.935078\n",
      "Iteration 33, loss = 0.30988115\n",
      "Validation score: 0.916251\n",
      "Iteration 34, loss = 0.30018500\n",
      "Validation score: 0.918295\n",
      "Iteration 35, loss = 0.29084582\n",
      "Validation score: 0.912186\n",
      "Iteration 36, loss = 0.28138591\n",
      "Validation score: 0.945086\n",
      "Iteration 37, loss = 0.27283246\n",
      "Validation score: 0.949983\n",
      "Iteration 38, loss = 0.26504586\n",
      "Validation score: 0.920007\n",
      "Iteration 39, loss = 0.25628484\n",
      "Validation score: 0.939524\n",
      "Iteration 40, loss = 0.24830731\n",
      "Validation score: 0.952361\n",
      "Iteration 41, loss = 0.24094335\n",
      "Validation score: 0.935768\n",
      "Iteration 42, loss = 0.23338123\n",
      "Validation score: 0.953383\n",
      "Iteration 43, loss = 0.22946868\n",
      "Validation score: 0.958993\n",
      "Iteration 44, loss = 0.22010533\n",
      "Validation score: 0.957020\n",
      "Iteration 45, loss = 0.21745224\n",
      "Validation score: 0.959136\n",
      "Iteration 46, loss = 0.20850854\n",
      "Validation score: 0.957163\n",
      "Iteration 47, loss = 0.20445273\n",
      "Validation score: 0.963652\n",
      "Iteration 48, loss = 0.19773837\n",
      "Validation score: 0.965768\n",
      "Iteration 49, loss = 0.19267759\n",
      "Validation score: 0.959136\n",
      "Iteration 50, loss = 0.18767317\n",
      "Validation score: 0.956235\n",
      "Iteration 51, loss = 0.18439028\n",
      "Validation score: 0.952099\n",
      "Iteration 52, loss = 0.17821177\n",
      "Validation score: 0.963938\n",
      "Iteration 53, loss = 0.17650923\n",
      "Validation score: 0.953026\n",
      "Iteration 54, loss = 0.16928718\n",
      "Validation score: 0.972210\n",
      "Iteration 55, loss = 0.16602726\n",
      "Validation score: 0.972424\n",
      "Iteration 56, loss = 0.16279124\n",
      "Validation score: 0.958066\n",
      "Iteration 57, loss = 0.15931907\n",
      "Validation score: 0.965744\n",
      "Iteration 58, loss = 0.15482063\n",
      "Validation score: 0.966386\n",
      "Iteration 59, loss = 0.15307961\n",
      "Validation score: 0.963034\n",
      "Iteration 60, loss = 0.14816154\n",
      "Validation score: 0.943280\n",
      "Iteration 61, loss = 0.14505273\n",
      "Validation score: 0.971996\n",
      "Iteration 62, loss = 0.14255443\n",
      "Validation score: 0.968288\n",
      "Iteration 63, loss = 0.13980921\n",
      "Validation score: 0.979128\n",
      "Iteration 64, loss = 0.13891438\n",
      "Validation score: 0.973542\n",
      "Iteration 65, loss = 0.13390489\n",
      "Validation score: 0.964270\n",
      "Iteration 66, loss = 0.13214460\n",
      "Validation score: 0.971188\n",
      "Iteration 67, loss = 0.12927061\n",
      "Validation score: 0.967717\n",
      "Iteration 68, loss = 0.12597009\n",
      "Validation score: 0.963605\n",
      "Iteration 69, loss = 0.12694086\n",
      "Validation score: 0.981006\n",
      "Iteration 70, loss = 0.12139940\n",
      "Validation score: 0.968454\n",
      "Iteration 71, loss = 0.12012216\n",
      "Validation score: 0.980126\n",
      "Iteration 72, loss = 0.11814246\n",
      "Validation score: 0.976133\n",
      "Iteration 73, loss = 0.11592597\n",
      "Validation score: 0.975990\n",
      "Iteration 74, loss = 0.11584269\n",
      "Validation score: 0.975990\n",
      "Iteration 75, loss = 0.11168138\n",
      "Validation score: 0.981149\n",
      "Iteration 76, loss = 0.11405490\n",
      "Validation score: 0.972020\n",
      "Iteration 77, loss = 0.10824649\n",
      "Validation score: 0.976775\n",
      "Iteration 78, loss = 0.10689064\n",
      "Validation score: 0.990372\n",
      "Iteration 79, loss = 0.10664572\n",
      "Validation score: 0.986355\n",
      "Iteration 80, loss = 0.10307292\n",
      "Validation score: 0.981577\n",
      "Iteration 81, loss = 0.10191176\n",
      "Validation score: 0.989944\n",
      "Iteration 82, loss = 0.10283163\n",
      "Validation score: 0.986949\n",
      "Iteration 83, loss = 0.09939137\n",
      "Validation score: 0.982646\n",
      "Iteration 84, loss = 0.10183926\n",
      "Validation score: 0.985000\n",
      "Iteration 85, loss = 0.09535582\n",
      "Validation score: 0.989303\n",
      "Iteration 86, loss = 0.09829861\n",
      "Validation score: 0.992892\n",
      "Iteration 87, loss = 0.09304015\n",
      "Validation score: 0.995246\n",
      "Iteration 88, loss = 0.09371642\n",
      "Validation score: 0.990087\n",
      "Iteration 89, loss = 0.09198324\n",
      "Validation score: 0.995840\n",
      "Iteration 90, loss = 0.08995926\n",
      "Validation score: 0.997504\n",
      "Iteration 91, loss = 0.08941719\n",
      "Validation score: 0.984881\n",
      "Iteration 92, loss = 0.09228092\n",
      "Validation score: 0.990681\n",
      "Iteration 93, loss = 0.09059834\n",
      "Validation score: 0.993582\n",
      "Iteration 94, loss = 0.08434960\n",
      "Validation score: 0.992036\n",
      "Iteration 95, loss = 0.08618363\n",
      "Validation score: 0.996482\n",
      "Iteration 96, loss = 0.08333073\n",
      "Validation score: 0.995246\n",
      "Iteration 97, loss = 0.08202271\n",
      "Validation score: 0.997504\n",
      "Iteration 98, loss = 0.08444654\n",
      "Validation score: 0.997504\n",
      "Iteration 99, loss = 0.07950050\n",
      "Validation score: 0.997504\n",
      "Iteration 100, loss = 0.08551929\n",
      "Validation score: 0.995246\n",
      "Iteration 101, loss = 0.07731706\n",
      "Validation score: 0.997504\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "(best_model) Tardo en entrenar el modelo  05 min.s y 25 seg.s\n",
      "Modelo guardado en mlp_model.pkl.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "#from catboost import CatBoostClassifier, Pool\n",
    "### Diccionario para almacenar los resultados\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "results = {}\n",
    "\n",
    "# Cargar o entrenar el modelo MLPClassifier\n",
    "model_path = \"mlp_model.pkl\"\n",
    "existe_modelo = os.path.exists(model_path)\n",
    "existe_modelo = False\n",
    "if existe_modelo:\n",
    "    p2f.reprint(\"Cargando el modelo desde el disco...\")\n",
    "    mlp = joblib.load(model_path)\n",
    "else:\n",
    "    p2f.reprint(\"Entrenando el modelo MLPClassifier...\")\n",
    "    \n",
    "    tunear = False\n",
    "    if tunear:\n",
    "        groups = df_complete['item_id']\n",
    "\n",
    "        # Usar GroupShuffleSplit para mantener los item_id juntos\n",
    "        gss = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "        train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        #train_idx, val_idx = next(gss.split(X_train, y, groups=groups))\n",
    "        #X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        #y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]    \n",
    "\n",
    "        # Definir los parámetros para GridSearch, incluyendo estrategias de validación cruzada\n",
    "        param_grid = {\n",
    "            'mlp__hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 100)],\n",
    "            'mlp__activation': ['relu', 'tanh'],\n",
    "            'mlp__solver': ['adam', 'sgd']\n",
    "            #'cv_strategy': [KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "            #                StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "            #                TimeSeriesSplit(n_splits=5)]\n",
    "        }\n",
    "\n",
    "        # Definir el modelo base\n",
    "        mlp = MLPClassifier(\n",
    "            max_iter=500,  # Número máximo de iteraciones\n",
    "            verbose=True,  # Imprimir información del entrenamiento\n",
    "            early_stopping=True,  # Activar early stopping\n",
    "            validation_fraction=0.1,  # Fracción de datos para validación\n",
    "            n_iter_no_change=10,  # Número de iteraciones sin mejora antes de detenerse\n",
    "            random_state=42  # Semilla para la aleatoriedad\n",
    "        )\n",
    "        \n",
    "        # Crear un pipeline que incluya escalado y el modelo\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Escalado de características\n",
    "            ('mlp', mlp)                   # Modelo MLP\n",
    "        ])\n",
    "        \n",
    "        # Definir los parámetros para GridSearch, incluyendo estrategias de validación cruzada\n",
    "        param_grid = {\n",
    "            'mlp__hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 100)],\n",
    "            'mlp__activation': ['relu', 'tanh'],\n",
    "            'mlp__solver': ['adam', 'sgd']\n",
    "        }\n",
    "\n",
    "        # Definir diferentes estrategias de validación cruzada\n",
    "        cv_strategies = {\n",
    "            'KFold': KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "            'StratifiedKFold': StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "            'TimeSeriesSplit': TimeSeriesSplit(n_splits=5)\n",
    "        }\n",
    "\n",
    "        # Configurar GridSearchCV con el pipeline\n",
    "        tracker = TimeTracker()\n",
    "        # Ejecutar GridSearchCV para cada estrategia de validación cruzada\n",
    "        for cv_name, cv_strategy in cv_strategies.items():\n",
    "            p2f.reprint(\"\\n---------------------------------------------------------------\")\n",
    "            p2f.reprint(f\"\\nEvaluando con {cv_name}\")\n",
    "            \n",
    "            #p2f.reprint(\"LLevo \",tracker.dime_que_llevo())\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=pipeline,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv_strategy,  # Estrategia de validación cruzada\n",
    "                n_jobs=-1,\n",
    "                verbose=2\n",
    "                #scoring=None,  # Puedes definir una métrica de scoring si no quieres usar la predeterminada\n",
    "            )\n",
    "            \n",
    "            #p2f.reprint(\"(2)LLevo \",tracker.dime_que_llevo())\n",
    "            \n",
    "            # Ajustar GridSearchCV\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            p2f.reprint(\"LLevo \",tracker.dime_que_llevo())\n",
    "            \n",
    "            # Mostrar los mejores parámetros\n",
    "            p2f.reprint(f'Best parameters: {grid_search.best_params_}')\n",
    "            \n",
    "            p2f.reprint('Testeando!')\n",
    "            \n",
    "            # Evaluar el mejor modelo en el conjunto de prueba\n",
    "            best_mlp = grid_search.best_estimator_\n",
    "            y_test_pred = best_mlp.predict(X_test)\n",
    "            \n",
    "            # Calcular métricas de rendimiento\n",
    "            accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "            roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1]) if len(set(y_test)) == 2 else None  # Para problemas binarios\n",
    "\n",
    "            #p2f.print(f'Accuracy en el conjunto de prueba: {accuracy_score(y_test, y_test_pred)}')\n",
    "            #p2f.print(y_test_pred)\n",
    "\n",
    "            # Almacenar los resultados\n",
    "            results[cv_name] = {\n",
    "                'best_params': grid_search.best_params_,\n",
    "                'best_mlp': best_mlp,\n",
    "                'accuracy': accuracy,\n",
    "                'f1_score': f1,\n",
    "                'roc_auc': roc_auc\n",
    "            } \n",
    "            # Mostrar los resultados\n",
    "            p2f.reprint(f'Best parameters with {cv_name}: {grid_search.best_params_}')\n",
    "            p2f.reprint(f'Accuracy on test set with {cv_name}: {accuracy:.4f}')\n",
    "            p2f.reprint(f'F1 Score on test set with {cv_name}: {f1:.4f}')\n",
    "            if roc_auc is not None:\n",
    "                p2f.reprint(f'ROC AUC on test set with {cv_name}: {roc_auc:.4f}')        \n",
    "        \n",
    "        # Comparar los resultados de todas las estrategias\n",
    "        p2f.reprint(\"\\n---------------------------------------------------------------\")\n",
    "        p2f.reprint(\"\\nComparación de estrategias de validación cruzada:\")\n",
    "        for cv_name, result in results.items():\n",
    "            p2f.print(f\"{cv_name}:\")\n",
    "            p2f.print(f\"  Best Params: {result['best_params']}\")\n",
    "            #p2f.print(f\"  Accuracy: {result['accuracy']:.4f}\")\n",
    "            #p2f.print(f\"  F1 Score: {result['f1_score']:.4f}\")\n",
    "            #if result['roc_auc'] is not None:\n",
    "            #    p2f.print(f\"  ROC AUC: {result['roc_auc']:.4f}\")\n",
    "            p2f.print()  \n",
    "\n",
    "        #mlp = results[0].best_mlp\n",
    "        mlp = results['KFold']['best_mlp']\n",
    "\n",
    "        p2f.reprint(\"Tuneando, no salvo a fichero el modelo.\")\n",
    "    else:\n",
    "       \n",
    "        tracker = TimeTracker()\n",
    "        \n",
    "        best_parameters = {'mlp__activation': 'relu', 'mlp__hidden_layer_sizes': (50,), 'mlp__solver': 'adam'}\n",
    "        \n",
    "        mlp = MLPClassifier(\n",
    "            activation=best_parameters['mlp__activation'],  # 'relu'\n",
    "            hidden_layer_sizes=best_parameters['mlp__hidden_layer_sizes'],  # (50,)\n",
    "            solver=best_parameters['mlp__solver'],  # 'adam'\n",
    "            max_iter=500,  # Número máximo de iteraciones\n",
    "            verbose=True,  # Imprimir información del entrenamiento\n",
    "            early_stopping=True,  # Activar early stopping\n",
    "            validation_fraction=0.1,  # Fracción de datos para validación\n",
    "            n_iter_no_change=10,  # Número de iteraciones sin mejora antes de detenerse\n",
    "            random_state=42  # Semilla para la aleatoriedad\n",
    "        )\n",
    "\n",
    "        # Entrenar el modelo con los datos de entrenamiento\n",
    "        mlp.fit(X_train, y_train)\n",
    "        \n",
    "        p2f.reprint(\"(best_model) Tardo en entrenar el modelo \",tracker.dime_que_llevo())\n",
    "        \n",
    "        \n",
    "        joblib.dump(mlp, model_path)\n",
    "        p2f.reprint(f\"Modelo guardado en {model_path}.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8566a166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procediendo a imputar valores faltantes en 'feature_category_literal'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▋                                                          | 5004/20562 [01:40<06:09, 42.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000)::LLevo  01 min.s y 48 seg.s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████████████████████▉                                       | 10006/20562 [03:20<03:33, 49.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000)::LLevo  01 min.s y 39 seg.s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████████████████████████████▍                    | 15003/20562 [04:59<01:40, 55.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000)::LLevo  01 min.s y 39 seg.s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████████████████████████████████████▉  | 20005/20562 [06:39<00:12, 42.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000)::LLevo  01 min.s y 39 seg.s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 20562/20562 [06:50<00:00, 50.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20562)::LLevo  11 seg.s\n",
      "\n",
      "Elementos actualizados 0\n",
      "\n",
      "Número total de grupos procesados: 20562, nº de asociaciones realizadas 0\n",
      "\n",
      "Asociaciones creadas (0:\n",
      "{}\n",
      "\n",
      "Categorías no asociadas (16):\n",
      "[59, 65, 41, 34, 57, 49, 38, 37, 36, 67, 6, 52, 43, 10, 71, 40]\n",
      "Archivo guardado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario para almacenar las asociaciones feature_category_id -> feature_category_literal\n",
    "category_id_to_literal = {}\n",
    "\n",
    "# Paso 2: Imputar los valores faltantes de 'feature_category_literal'\n",
    "p2f.print(\"Asignando 'feature_category_literal'...\")\n",
    "\n",
    "if df_missing.empty:\n",
    "    p2f.reprint(\"No hay valores faltantes en 'feature_category_literal'. Nada que imputar.\")\n",
    "else:\n",
    "    p2f.reprint(\"Procediendo a imputar valores faltantes en 'feature_category_literal'...\")\n",
    "    num_asociaciones = 0\n",
    "    failed_feature_category_id = []\n",
    "    group_count = 0  # Contador de grupos\n",
    "    elementos_asociados = 0\n",
    "    for item_id, group in tqdm(df_missing.groupby('item_id')):\n",
    "        \n",
    "        group_count += 1  # Incrementar el contador\n",
    "        if group_count % 5000 == 0:\n",
    "            p2f.reprint(f\"({group_count})::LLevo \",tracker.dime_que_llevo())\n",
    "            \n",
    "        p2f.print(f\"\\nProcesando grupo {group_count} para item_id {item_id}\")\n",
    "        #print(f\"Contenido del grupo:\\n{group}\")\n",
    "\n",
    "        if group['feature_category_literal'].isna().any():\n",
    "\n",
    "            X_missing = pd.get_dummies(group[['feature_category_id']])\n",
    "\n",
    "            missing_cols = set(X_train.columns) - set(X_missing.columns)\n",
    "            for col in missing_cols:\n",
    "                X_missing[col] = 0\n",
    "            X_missing = X_missing[X_train.columns]\n",
    "\n",
    "            for i, (index, row) in enumerate(group[group['feature_category_literal'].isna()].iterrows()):\n",
    "                feature_category_id = row['feature_category_id']\n",
    "\n",
    "                # Si la categoría ya se asignó previamente, usar esa asociación\n",
    "                if feature_category_id in category_id_to_literal:\n",
    "                    elementos_asociados += 1\n",
    "                    assigned_category = category_id_to_literal[feature_category_id]\n",
    "                    df.at[index, 'feature_category_literal'] = assigned_category\n",
    "                    p2f.print(f\"Reutilizado '{assigned_category}' de asociaciones anteriores para 'feature_category_id' {feature_category_id} en el índice {index} para item_id {item_id}.\")\n",
    "                else:\n",
    "                    # Predecir solo si no hay una asociación previa\n",
    "                    predicted_categories = mlp.predict_proba(X_missing)\n",
    "                    top_indices = predicted_categories.argsort(axis=1)[:, -20:][:, ::-1]  # Obtener los 20 candidatos más probables\n",
    "                    decoded_candidates = [[encoder_category_literal.inverse_transform([idx])[0] for idx in indices] for indices in top_indices]\n",
    "\n",
    "                    # Evaluar candidatos posibles con las nuevas condiciones\n",
    "                    possible_candidates = []\n",
    "                    for cat in decoded_candidates[i]:\n",
    "                        cat_length = len(filtered_category_data.get(cat, []))\n",
    "                        num_possible_values = category_value_counts.get(feature_category_id, 0)\n",
    "                        is_in_missing_categories = cat in missing_categories\n",
    "\n",
    "                        if cat_length == num_possible_values and is_in_missing_categories:\n",
    "                            possible_candidates.append(cat)\n",
    "\n",
    "                    if possible_candidates:\n",
    "                        p2f.print(f\"Posibles candidatos para {feature_category_id}: {possible_candidates}\")\n",
    "                        assigned_category = possible_candidates[0]\n",
    "                        df.at[index, 'feature_category_literal'] = assigned_category\n",
    "                        category_id_to_literal[feature_category_id] = assigned_category  # Guardar la asociación\n",
    "                        p2f.print(f\"Asignado '{assigned_category}' a 'feature_category_literal' en el índice {feature_category_id} para item_id {item_id}.\")\n",
    "                        num_asociaciones += 1\n",
    "                        elementos_asociados += 1\n",
    "                        # Eliminar la categoría asignada de missing_categories\n",
    "                        if assigned_category in missing_categories:\n",
    "                            missing_categories.remove(assigned_category)\n",
    "                            p2f.print(f\"Eliminado '{assigned_category}' de missing_categories.\")\n",
    "                    else:\n",
    "                        # Añadir solo si no está ya en la lista\n",
    "                        if feature_category_id not in failed_feature_category_id:  \n",
    "                            failed_feature_category_id.append(feature_category_id)\n",
    "                            \n",
    "    p2f.reprint(f\"({group_count})::LLevo \",tracker.dime_que_llevo())   \n",
    "    p2f.reprint(f\"\\nElementos actualizados {elementos_asociados}\") \n",
    "    p2f.reprint(f\"\\nNúmero total de grupos procesados: {group_count}, nº de asociaciones realizadas {num_asociaciones}\")\n",
    "    p2f.reprint(f\"\\nAsociaciones creadas ({len(category_id_to_literal)}:\\n{category_id_to_literal}\")\n",
    "    p2f.reprint(f\"\\nCategorías no asociadas ({len(failed_feature_category_id)}):\\n{failed_feature_category_id}\")    \n",
    "    \n",
    "    # Guardar el resultado, para iterar de nuevo, en vez de item_features_semirelleno_con_literales_actualizado, \n",
    "    # usar este otro, cambiar este nombre y asi sucesivamente,\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP.csv', index=False)\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP_2.csv', index=False)\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP_3.csv', index=False)\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP_4.csv', index=False)\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP_5.csv', index=False)\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP_7.csv', index=False)\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP_8.csv', index=False)\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP_9.csv', index=False)\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP_10.csv', index=False)\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP_11.csv', index=False)\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP_12.csv', index=False)\n",
    "    #df.to_csv('./item_features_rellenado_con_literales_MLP_13.csv', index=False)\n",
    "    df.to_csv('./item_features_rellenado_con_literales_MLP_14.csv', index=False)\n",
    "    \n",
    "    p2f.reprint(\"Archivo guardado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7763051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo original de base, sólo con los rellenos, guardado con éxito.\n"
     ]
    }
   ],
   "source": [
    "#df_complete = df_complete.drop(columns=['item_id_2'])\n",
    "df_complete = df_complete.drop(columns=['feature_category_literal_encoded'])\n",
    "\n",
    "\n",
    "# Me quedo sólo con lo que he asignado de literales, mi encoder/decoder, por si ya no hiciera nada más, no asignará más...\n",
    "yyyyMMdd_HHmmss = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "df_complete.to_csv(f\"./item_features_encoderDecoder_{yyyyMMdd_HHmmss}.csv\", index=False)\n",
    "p2f.reprint(\"Archivo original de base, sólo con los rellenos, guardado con éxito.\")\n",
    "\n",
    "# Paso 3: Validación y Testing\n",
    "#p2f.reprint(\"Validando el modelo con el solo con los rellenosconjunto de prueba...\")\n",
    "#y_pred = mlp.predict(X_test)\n",
    "#p2f.print(\"Reporte de clasificación en el conjunto de prueba:\")\n",
    "\n",
    "#print(encoder_category_literal.classes_)\n",
    "#print(\"Clases en y_test:\", set(y_test))\n",
    "#print(\"Clases en y_pred:\", set(y_pred.flatten().tolist()))\n",
    "#print (y_pred)\n",
    "#p2f.print(classification_report(y_test, y_pred, target_names=encoder_category_literal.classes_))\n",
    "\n",
    "# Guardar el resultado del modelo en el conjunto de prueba\n",
    "#test_results = pd.DataFrame({\n",
    "#    'item_id': filtered_df.iloc[test_idx]['item_id'],\n",
    "#    'feature_category_id': filtered_df.iloc[test_idx]['feature_category_id'],\n",
    "#    'true_category_literal': encoder_category_literal.inverse_transform(y_test),\n",
    "#    'predicted_category_literal': encoder_category_literal.inverse_transform(y_pred)\n",
    "#})\n",
    "#test_results.to_csv('./test_results_catBoost.csv', index=False)\n",
    "#p2f.reprint(\"Resultados de prueba guardados en 'test_results_mlp.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7f1a518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420314"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c9eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
